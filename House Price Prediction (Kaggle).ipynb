{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition for House Prices : Advanced Regression Techniques\n",
    "\n",
    "## Pulkit Khandelwal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading csv files\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying whole rows and columns\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "3       Norm     1Fam     2Story            7            5       1915   \n",
       "4       Norm     1Fam     2Story            8            5       2000   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3          1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n",
       "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "2          GLQ         486          Unf           0        434          920   \n",
       "3          ALQ         216          Unf           0        540          756   \n",
       "4          GLQ         655          Unf           0        490         1145   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
       "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
       "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "2       1786             1             0         2         1             3   \n",
       "3       1717             1             0         1         0             3   \n",
       "4       2198             1             0         2         1             4   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "3             1          Gd             7        Typ           1          Gd   \n",
       "4             1          Gd             9        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "2     Attchd       2001.0          RFn           2         608         TA   \n",
       "3     Detchd       1998.0          Unf           3         642         TA   \n",
       "4     Attchd       2000.0          RFn           3         836         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "3         TA          Y           0           35            272          0   \n",
       "4         TA          Y         192           84              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
       "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
       "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice  \n",
       "0       WD        Normal     208500  \n",
       "1       WD        Normal     181500  \n",
       "2       WD        Normal     223500  \n",
       "3       WD       Abnorml     140000  \n",
       "4       WD        Normal     250000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "BsmtQual           37\n",
       "BsmtCond           37\n",
       "BsmtExposure       38\n",
       "BsmtFinType1       37\n",
       "BsmtFinSF1          0\n",
       "BsmtFinType2       38\n",
       "BsmtFinSF2          0\n",
       "BsmtUnfSF           0\n",
       "TotalBsmtSF         0\n",
       "Heating             0\n",
       "HeatingQC           0\n",
       "CentralAir          0\n",
       "Electrical          1\n",
       "1stFlrSF            0\n",
       "2ndFlrSF            0\n",
       "LowQualFinSF        0\n",
       "GrLivArea           0\n",
       "BsmtFullBath        0\n",
       "BsmtHalfBath        0\n",
       "FullBath            0\n",
       "HalfBath            0\n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAE6CAYAAAAodIjdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABCZklEQVR4nO2defxtY/X43+veawpXRDJ0zUOTWYZkSJFChaikEqWSIQ2/UrqGqFRSoUxdUioi0YC4LhkuLncilFCo+CJRZFy/P9az79lnnz2e4XP2/pz1fr3O6/M5+zzP3s/e+9lrr2c9a61HVBXHcRxn7Jkw7AY4juOMKi6AHcdxhoQLYMdxnCHhAthxHGdIuAB2HMcZEi6AHcdxhsSk0gUXXmng/mpP//0Pbd8XW/GNgz6k4zjjhKT8KMNYyJjnn31Qsn4rLYC7wQWq4zhjxWIrvrFQCNdNBknZQIxBa8BpF65uF8txnPriGrDjOEPHR57NoTaTcN5JHGcwdKMZOmPDwDTgqm9h7ySOMxhGVblJO++6yZmBCeBRvemO4zhlqY0N2AW24zj9pG7abhq18YIAnzxwnH4xqs9S0XkP47o0wguiCW8rx2kKoyJw46TJkLrLldpMwjmO0x/82WsOtZmEKxPF4jhOdZ7++x9cCNcUN0E4zghQ9fnq1W3UBX45aiOAHccZDIMQhi5g+4NHwjmO4wyJ2ghgx3H6Q5Hr1XiliUpcbbwgRqWTOM5Y0ERh1CtNlCG18YJwHKc/uBtac6jNJJy7oTlOf3CB26Lu5hg3QTiOM26pu1xxE4TjjDPcBNEc3AThOM64ZKTzATuOMxxGVeNNKnF1E7Zp1EYAN+FiOU4T6Mez1MRQ5DKml7rJmdpMwjmOMxhGNRS5bsI2jdpowG4Ddpz+0ATh6Bi18YJw4es4/cFHn82hNhqw4zj9wQVuc6iNAHYThOM4vVDmxVM3GVMbAQz+5nacfjGqZoimnXdtVkVOezPV/eI5Th1xN7Ty+KrIARe2jjMYRtUNrQnURgBD84YPjlNH/LlpDrURwHUzjjtOU3FFpjl4JJzjOM6QqI0G7G5ojtMfXNlpDrWJhHMcx+mFJipxtVkVuWkXznGcetFEGVIrE4TjOL3j8y/NoTYCGLzjOE4/8OemOdRGADdx+OA4dcQVmeZQGxuw4zjOqFEbDdjf0o4zGAaRI6GOuSCaSG2S8YAPnRzH6Y2qL5thJ+OpjQnCbcCO4/RCE2VIbQSw4zjOqFEbAezmBsdxRo3aCOAmDh8cx3F6oTZeEI7j9AefzG4OtRHATUyk4ThOs6jby8jd0BzHGTc0zQ2tNgnZXft1HKcXmihDPB+w44wzfCTZHGrjBeGdxHGcUaM2k3BNHD6MZ3q9H8kXqmtlY4df2+ZQGwHs1It+P8QuFBynEzdBOI7jDImBasA+7Gwu/TAJuRlieIzitU6LJaj7edfGDzjtga/7xXOcOtI0IdQvBpH3uB80wg/YcZz+4M+akXYd6jbZX5tJOA9FdhynnzRBntQmEKMJF8txmoCPPptDrTRgx3F6x5+l5lAbAQz+5nacfuDPUXOojReE4zj9Y1SFcB3PO88LojYC2N3QHMfphTLCdxgC2t3QHGeE8GfPaMLEfm1swO6G5jj9YVQFbhOpTS4IF76O44watfEDdhynP7gJojm4CcJxnHFJE0KRa+MFAf7mdpx+MarPUtMW5XQbsOOMM1z4NofamCAcx3H6SRNePG6CcBxnXOD5gHugicMHx6kjrsg0h9oIYMdx+oMLXKMJXhC1EcDuhuY4/cE1YKMJ8qQ2AtipF74oZ3NJKjODso0W7Xes728TlbiBTcJVfdg8G5rjOL1Q1xf8UCbh6nLyjuOMJmW04WHLqdqYIJo4fBjP9HoviswPaWWc/lBXTXCsacIknJsgHMcZF7gfcAwXno7jOPnUJheEC2zHcUaNgdqA3RblOM5Y0cR5pIEK4CoCt2kXznHqyqgqPt0syjlsfFFOx3HGJXUTtmnUZhKuicMHx6kjruw0h9r4AbvwdZz+4KNPY6RNEI7j1INB+MfWLQ9EGnUTtmnURgDX4YY5juOMJb4ihuM444amLcpZGw24CcMFx2kCo6rINFGG1EYAO47TH0ZF4I4HPBTZcRxnSNRKA3Yh7Di9M6omiCQj7Ybm6SgdZzj4c2PUTdim4ZFwjuM4Q6I2NmDHcZxeaKLmXxsB7Nqv4zi90EQZUhsbsOM4/cGfvebgNmDHccYlI+0FUZW6XRjHaSqu8RpNkCm1sQE7juOMGrWxAbsJwnH6g9uAm8OYacAuXB1nbEgK3FF59pr4oqnNJNyodBLHGTSjqgE3UYbUxgThOI4zatRGA3YbsOM4/aQJbmi1WhHDcRynWwax9l0/aOyKGG62cJzquPmvOdTGD9g7ieM4o0ZtNGDHcfrDqCozTZxHqo0G3LQL5zhOvWiiDHEN2HHGGW4Dbg610YC9kziOM2rUJhCjicMHx6kjrsxkU7drU5tADMdx+oObILKp27WpjQ24iTOYjlNHhi1U6kITIuFqI4Adx+kfddP0xoKkElc3YZtGrQTwKHQSxxk0oyh8oRkCN0mtJ+FGpeM4jjOa1GYSzm3AjuOMGm6CcJxxhj9HzaE2AthNEI7jjBq1sQG7CcJx+sOoTsI1kVolZPeO4zj9YVSfpaLzHsZ1GUpCdg9Fbja93o86dPxRZhSvb1qfrbtcqY0XhFMv+n3/vD84Tie10YDdBuw4Tj8Z6VDkqhpP3S6M4zjNpgkypTb5gB3HcUaN2ghgtxE6jjNq1EYAO47j9EITlbhaR8I5jlOdUXX5a6IMqY0AdhynP4yKwB0PuBua4zjOkHA3NMcZZ4yqCaKJuAnCccY53Sg3vaYOcKFfjtoIYDdBOE5/GAvh5wK2P9RGADuO4/RCmhJXlBRq2NRGANftwjiO0yw8G5rjOEPHJ+GaQ20EsNuAHWcw+CRcfamNAHbh6zj9wSfhmkNtBLDjOP3BTRDNwSPhHMdxhsSYZUNz4eo4Y0PdXa8GRRM1fQ9FdpxxRj/csZo4CddEGeI2YMcZZ/gkXHOoTUJ2v6GO44watdGAmzh8cJw64l4QzaE2AthxnP7gArc5uAnCcRxnSLgG7DjjkFE0QzQxlqA2ArhpF85x6swoCNwkTZQhtRHAjuM4/STtJVQ3IV0bAdzE4YPj1JFRND+k0QR5IqpaquCkhVcqV9BxHGcIlBG4w3gZPf/sg5L1W2004LSLN6pvbsdxeqcJ8qM2AthNEPWi13tRJiFMEx6QJuImCKOuGnGcgZkgunngvOM4Tn8Y1Wep30mH+sFQTBCeDc1xhseoCNw4TZQhtUnI7jiOM2rURgN2G7Dj9AdXfppDbSbhXPg6zmDwVZHrS20EsOM4/cETshseCVcBN0E4Tn/ox3M0HjTgJsiT2ghgx3H6Q5oy02+BWAcBm6TMeddNKNdGANftwjhOk6mjgBw0TZx8rI0AdhzH6SdNUOpq4wfsNmDHcUaN2vgBu/B1HKcXysicusmZWmnAjuP0ThNtof2gbsK1DLXRgGF0O47j9BN/bpqDJ2R3nHHIqCozng2tSzxfrOP0j1F8dtwE4TjO0BlV7TeJhyJXwN3QHMfpJ02QJxOG3YCIJlwsx3GcflIbDdhxnP4wqiaHJlIbAewmCMfpD24DNppgA66VG5p3HMfpD6P6LLkbWqBqB6jbm8lxmsyoCNw4TZQhtZmEcxzHGTVqE4rsNmDH6Q+jan5oIrXRgF34Oo4zatTGBuw4Tn/wZ605uAliHNCEBRIdx+mkNn7ATve4gHWcZipxtRHATbtwjlNXRtX810QZUhsB7DhOfxgVgZuk7kvQp1EbAdzE4YPjOPWhifKjNgK4iRfPcerIqJogmoi7oTnOOMOftebgbmiOM87ox3PUa+6WOrwEPBtaRVxrdhynFzwbWpfU7c3kOE1lVBWZJsqQ2uSCcBzHGTVqI4BH5S3tOI4TURsviCYOHxzHcXqhNhqw4zjOqOFuaI4zznBzXnOojReE4wwC9wgwRuG8m6jE1UYAN+3COc1gFARPklEUvlDuvOsmZ2ojgB3H6Q+jInDHA7WZhPNO4zjOqFEbDbhuQwPHcZpNE2RKbQSwUy967bxFybF9xDM4/Fo3h4El4+mmE3jHcRynW7pRGsZtMh4Xno7jjCXuhtYjLrQdp3dGdSTZNOELNRLAaRdvVDqO4/QTf26aQ22S8TRx+OA4dWRUNeAmUhsbsAtfx3FGjdoEYjiO44wcqlrpA3x00HUGXX68HKOObfLzrk/58XKMOrap2zod++jioLMGXWfQ5cfLMerYJj/v+pQfL8eoY5u6rZP8uAnCcRxnSLgAdhzHGRLdCODTxqDOoMuPl2PUsU1jcYw6tmksjlHHNo3FMerYpm7rtFE6F4TjOI7TX9wE4TiOMyRcADuO4wwJF8CO4zhDohYCWEReO+w2OM6gEZGJIvLjEuWWyfuMRVv7gYhMGXYb6k5uLggR2S3vd1W9sKD+VsBaqjpNRJYDllDVe1OK/kBEFgbOAs5V1cdzW237XgN4QFWfEZFtgfWAH6XV7fY8ROQlwKeBKar6ERFZC1hHVX+dKHdYwf5PyPu9zHXq5hhV64jIfCBtVlasuK6Xt7+U4y+hqv9J2T4ZWE5V/5LYvp6qzsvYV9o9/DcwX1UfTpTdKK9dqnprovzmqjozr04eIjIRWJ7Y86Sqf0s57gsispyILKyqz+bs8hbsPggwBfhX+P+lwN+A1bptaxoisgiwO7Aq7edwdKJc1f5xEbBRqHuBqu5eoU1rA58FVkm06U0pZXcEllTVXyS27w08rKq/T2zv6nkVEQH2BlZX1aPDC+YVqnpTubPqpCgZzy7h78uBLYHp4ft2wAwgUwCLyFRgE2AdYBqwEPBj4A3Jsqq6VRBuHwZmichNwLTkhUtwAbCJiKwJnAlcDJwLvK2P5zENexi2CN8fAM4Hfp0ot2T4uw6waWhLdNxrcs6hynXq5hhLZmzPYueK5Yv4IyZAFiAiewInAg+LyELAh1T15vDzWYQHNoX9sPtwVfi+LTATWFtEjlbVc2Jlv5XTJgWSD/EptATFDaq6RUetDETkIGAq8BDwYuwYWS+r+4DrRORi4L8LGhV76FV1tbDvHwAXq+pvw/edgDeXaNOTtATlwlif+q+qTs6o8ivsZXYL8EzOrqv2j/hKEKtXrHs+8APgdOCFgrJH0XrG41wJ/BJIypGqz0XEKdg9fhNwNPAkJoc27XJ/5UKRMYGzQuz7CsCFBXXmYDdgdmzbvII6E7E38YPAHcCdwG4ZZW8Nfz8LHBT+n12w/0rnQQg1TJzD3Jzyl2Nv4uj7ksCl/bxO3RxjkB/gsIzPp4HHMs53hfD/6+P3OO/+AZcAy8e+L4+9OJcBbuvxHGan/V+y7t3AyyqUn5r2ySh7S1afrNjGdwLH5fze0/XL2e+taf+XrNtx7jll856XXJnTzfmUlQdlPmXTUa6qqv+IfX8IWLugzrOqqiKiACKyeFZBEVkP2Bd4O/a22kVVbxWRFYEbSNdQnxOR9wIfpPX2W6jP5/GsiCxG0CaC2SNPQ5gCxIeWz2LDujxKX6dujyEii2Ia5GuARaPtqvrhjPKbA98DXoVpUBPJ1qCOA74BPJ/yW9ocw8ToHqjqTSKyHfBrEVmZ9OFtxKqq+lDs+8PA2qr6mIg8l1UpzC+8mvbz/lGynSKydGhv9L/Eyj+W0677Me2xFKp6VNmywCMi8iVsRKTA+4FHK9SPjnmRiHw+p8j1IvI6VZ1fZn8V+sf6IvIEdi0Xi/0fmtXZn2I27ktE5BOYBrvgmcu4F4uKyCRVbeuDYYS1WM55VHouMJkzkZY8WI7WqKcrygrgGSJyGfDTcPD30BoKZnGeiJwKvFREPoKZF07PKHtS+O1wVX062qiqfw8dMI19gY8Bx6rqvSKyGtZR+3keU4FLgVeKyE8ws8CHcsqfA9wkIr8M+38XkHzYk1S5Tt0e4xxM09wRGzrtjY0wsjgJuzbnY+aRDwBrZpS9FbhIVW9J/iAi+6eUf1JE1tBg/1XVfwQb/kXYg5DFH0Tk16FNYCOla8IL6/G0CsG8sy0mgH8L7ARcS+f1WgobfkfCIW4jVlKGzzE74j1Yv/oN7YIiaV/fCrMd/ih8/wWmvQN8RVWn08l7sT4Y3etrwrZcEvbyCdg97Hi5xWy6k4B9ReSecA5FNv9S/UNVJxa1NYW4/RtshLtgl6SbMi4ETheRT6rqf2GBIvNdcsykVH8uvovdi+VF5FhgDyBLPpWidCRcuKlRlvVrVPWXJeq8BdgBu5iXaY5NN2iaU1T1rlIN6r7Ou4Ctw9fC8xCRlwGbY+cwU1UfKSi/MbBVbP+zS7Sp9HXq5hgiMltVNxSReaq6XtAMLtOUCY1QfpaqbhKVD9uuV9UtU8quAzyadl1EZPmE1oqIrI9pS3cnti8E7KmqP8lok2BC9w3YdboWuEBzOnAQMOtjQ8b1RWR54AxVTbMXViII9yxUOyewrsRMZX+Mte1DwOKY4vHWRPmJwNmq+v4u2jYt9vV5zO58unZOVq6Stx9V/WvG/kv1D7FJ7OdU9bnwfR1sjua+MvKjLCIyCfgKsD/wV6x/vBKbGzoiOn5KvUrPRaizLrB9+DpdVfMEdjH9so/08sFMCHcB94bvG2CTD32tE8otH+ruDLy8RPndgBOwiZ13lSg/EVgRMxVMwV4Q/b5elY4B3BT+XgO8FlgWuCen/DXY0PJHwPHApyhp6wIWL/h98zHsV9F53wJMxh7M21PKrQIsFfu+HfCdcN4LFxzj3SW33Zz4fmHs/+sy9n1Z0fH7dJ3WABYJ/28LHAy8tNf+EcqtFf5fE3gMM11cCXytoE0HxtsALA18oqDOYsDrwmexCv2j1HMRym4Urs9BwEY9X/uCgz0JPJHyeRJ4oou692Mq/OqJsrdgw8DZsW1FE3ZpdeYX1NkTe0OeHTrPvcAeOeVPwSa99g2fS4GTc8ofBDwC3A7MA+ZnnUfs+iSvU+61rXKMWJ39QwfeBhsyPwx8LKf8KqEzT8aGwCcAaxYcY0vM6+Fv4fv6wCkp5eITMzeU7qj2IvwzZm8t2wdPwVy3Phbqzsa8a5LlbgRWDP9vEK7vp0M/OaPgGB2TSxnb/pyzj7sztp8K3AwcQWyCs6A97wCuw4TdY6H/bhV+WyqjzhzMDLEm8Bfg28Bve+0f8ecROCZ6djDhXfSszknZNjun/AqYFnxh+BxOweRoxnNxQE75L4fn7UjM82Iu8KWyfTh1n71ULji5o4ADsFn6ycBHwwnsBcxIPgDJC0yxUOmmzlxiWi+wHPleDbcTzDTh+wRSNKjY75VmxLu8rgM/RpftuhEb9sXvR8fsOl16HITzflUP7VsVWC/jt3mx/78JHB+731kv0J0wbe4hzDYYfc4iaFaJ8pcAb0/ZvjPwm4xjTE375JzjJ4BZmJvU5PB5E3B9eO5S+zqt2f3PUdKjqOQ1j1/X64B3xr7njqgw5SL+7E3MevYwAXp/kDm7Yi+hSECuBpyTKP9H4IvAGhXP5w5g0dj3xYA7erlGg1yW/q2qulns+2kiMlPNgfnwRNnbROR9wMTgD3ww1mny6KbOBG23gz1KfjTgXdgQP7KFvRLrGFlUmhEHEJFvAj/UYBssQTfH+HLadk3YKWPl7yVl0kZVc305VfV+M9UuIM1/s1uPg4e0or0t2Punq+q/VfU+EXmpiLxTVS9KFo39/ybgC6EtLybOJ87fMWG3KzYai3gSG5In+RTwGxHZg9Yk38bYyCHVv1areUyAjY7ekLiG00VkF8yHPSsAIfIo+gAlPIoq9I95oX8/iGnXl4f6Ly0+FS7HJqh/EI71MWwEmsY3gF21fS7kV2Giei426o7zXmwS8XIReQSblP+5tntIpXEf5i3xv/B9EWzE0DWDFMAvijndR9Epe8R+S968g7A30jPYxbgMG7Lk0U2dS2NeEGBawW9zyr8MuEMsMATM4foGMSd6VHXXRPlSM+IJ7sRmcCdhgRg/VdU8AdvNMf4b+39R7IHPE2abJMq/m9aMfRb3i8iWgIpFNR6ccYylqOhxEJglIj/HvCXi5503yz1VY5M9qvp4mDy7KFFuuoicB/wDG5JOBxCRFWh3+Ws1VHUuMFdEztWMSZ5E+bvF3C33puXtcQ1mCvpfvGyXHhPRcTpeYKr6qIj8VVW/n1GtqkdR2f7xEeAQbPSxg6o+Fba/Ghtp5PFZbAT9cayvXA6ckVF2CU2ZiFbVOSLyEHZ+8e1zMcH8heBStxdwo4jcjT1/WV5IzwC3i8jvsb76FuBaEflu2O/BBefUwcDyAYvI6thExhZYY2diWsCDwMaqeu1ADlzcrt0wDwKhwAtCRLbJ25eqXp0oPzWjXKEmE2aI98Xeztdhs9ZXpZTr+hixfSyCTVjuWKHOtaq6Vc7vy2L3+82YdnsZcIiqVvZbzdj/tJTNqtk+m8Rn6WPb5qvq6xLbBHsIVwDOU9UHw/YNMZPVZTnHWAv4Kp2+xqkvEhH5FHC+qj6Qs89KHhOxejdiC0XOTWxfHzgtMSLtK3n9Q0Q21oSboojsoqqXZJSPTD+lcsSIyB3Alqr6r8T2ZbAJzleV2Me2mO371aq6SEaZD+btQ1XPLtPeOAPTgFX1HtLDA8FciBCRS8hxvk/RMBGRE1X10Ky6aXUSXAc8F+oWxXC/DvhJ8sbmtPeo0MYl7WtnHoQ0gsvRuuHzCPZ2PkxEDlDV96Qdo0deQk5oqLTnUoj8SHPDN9Xc0PYuOnBwfXo80vLFAjHeiQ3vTtaMHAmqum/a9gJmicgJwMnY/T6IdnNBtG8FfpayvUOrSmEaZpv9NuY9sS/tJo0kk4HLROSxcMxfaMJVD5icMEn9ORJgIvLVnH1/Grg4vKwif9pNsWClDnc2ETlPVfeUjBwPyZdXrF7V/nG6iHxQQ6BHMHccitnFOwimn7kiMkVTcmqk8G3MnPAZ2s07Xw+/pSIim2IKz+5Y/zuNlp95Go9ik5M9BV+0tWGAGnBhlElVDTPU2VhVb8mqm1YnVndPzF40A3tI3gh8VhNJPGLlv4LZim4Ffoj5CGZeMLGoq3NoDcceAT6gqrfn1DkBe1FNB87UWGIPEblLVdcJ/0/EZm1XBn6nqtfHyn1JVb+Sc4z4AzYRm3w8WlVPyigf17wjP9Jvao6/dWzEs3k41g3Ap8KLOF7uRsyd7+8isgFwBaZBrof5jO6fKP85VT1eRL5HupDIHPaJOeMfgWnl0TD2Kxqc9VPK74Y9tC8P5aOAhKwcCojILaq6cVyzFpE/qOobs+qEMuthWvfuWFKpN8d++7OqrpVR725VzQqKQczX+UDsuRNsIvlkVf1nStkV1AJhVknbl2b7AVfqH6Fv/AJ7QW+F2Zp3zjO1ich07OVxE+05M1IVLBHZGZtEjMw7twPfSNOyReQ47Nr/C3sJ/ixvRBKr92NsRH8B5k3Tmw8wDNQL4nzMJvsX7A18OfCdPu7/kDLbEr9X8oIIZQSLlPkZNhN/HBmzp9gk4Hax79sC1xfs/8PASzJ+Wyr2/xlYsqFDMe3mhNhvuXH2mNtQ9FkJmDSA+z0T2AcbVU3CNK4bU8pV8jjAwtIJfajj0+dzqOxpgY2oJmCuT5/EIhPvKlHvFZhGfl3yvOnCYyKl7GJY5r6+3uceru3amPfBZZTz0d0m7dOntkzFwti7qTsZs03PxJSMjxLLzVJ5fwO84LPD33nh70LYjHS8zHzMqyD5mV9CMKb5Ws4uqDM/8X1CcltGvfWxDF53At/H/EmPTymX5oxedB5XltwWF1yTsOHShdhMbNF5vxmbFDsYs5Xlld0Qm4C5NXxOI/h4kiO4M4TtzLx7EPa/Y9o5ptQrFfAQtp8Y/l6CZY1r++QcIzUgouB6bQosgY1MpoV7khlsgk0qzcA0tKMwm2OyzJqYB840TEgfhLm3/amM4KBikBIVfKyr9A86n+9/hnbNy7vXsfrLYy+d3KApzB3wu1mfnHqVgz1CuWUxReg+4Hfh2h1Ute+oDtYNLZoZfjwMzf9JZ9KYNPcbwTpz0lXNfjT70fuA1SJvhMCSFCcqKeUFIRZTfpKIHIxpWo9gGuhnVfW5MEnwZ2zIE+ceETkCM0OAaYH3ZpzHopgtdllpd8WajEW5JVk4+kct6chHxdzLpmMCIO0Yr8RSDT5Jy/NgdxF5GvOV3EdVz4iV3x0bgh+HRTgJZkv7hYh8HHN03550rhJL+PIzzFSwF+Z2tUxoczQ7X9njIPAFOu1zadugdf2LZtqTVPa00FYqzf+QmG3PYBXgUFWdk7PP0h4TGRyJZZqbEfY3R0RWzSl/PDbSyB1Sd9E/uk5vmmIu/J6IZJkLZ3V5mI+o6snRF1X9l1g+llMSbdlNVS8Uc+f7MBY5eA7welV9WCzk+g7sRVCNbqR2Sc0gijLZmnJRJhtgN/U+LEHOJzPKrYIN7W+gfXiyESWG1pjN7QTMOJ8aWkzLMf1oYJWMMh1D1XC+36WlHZwILJ1R/xBMOD8Trs+94TM37dwxreOtGdf5uYxjXIzl201u/0DUxsT2eVjWsWT5VTHfx7yUhvfmfO6JlRPMrv4pYKXY9g2JacOx7ZUCHmL1JgI/rthnp6V8fphRdllsKHsw9gL8PnAb9sIrihosFc4artHKXTx7lYKUKKn5d9s/sHmBZArVzQqOVdlcmNj/EiXPpzDYg5Y8+BGwdca+tq96n1QHa4JYrWgbZhf6Mvb2uDZ0yL8Oqk0V2l41d+mi2AoPye3LE4ucyahbeuiCmUxyTQiJ8n/K+e0BEsM64I855QvtmgO6F+tjo5C/0m7/3Y2Ml1us7sByKWBzGseFl8MfMb/VdTHf1xk59Y7AhuZHURDOGgT87cAfsOHy8iXbdiY2SpwHrBXa+IOc8t8Bfo55BOwWfVLKddU/MJNdMqK0aN6isrkQy+cwO/SVv2GjvtfklP8GNoLaHgvAOQ/4Vkq5SvKgymeQXhC3qupGiW23qOrGse8vYp1rPw3ZsUTkHs2JuIr8DaU96z+Um7EuNcstIs8DT3XuIbP8aVhS9AsT2/fG4vA/ntKWTYH7NcxOi8gHMO38r8CRmhERJhVWbMiaMQ8mlLs0MdMuInOxoejfEttXAS7RnCWJRGQW5ilSdkmpSh4HIrKQlgh4SNQ5FdM2LyZj9YlQrrKnhYjMVcuwJpjSMCX22xxV3SCjTXcAG2owJYhl9LtVc3xV8zwmMsq/BAtS2iFsugzz/kg1X0hJH+tu+0fa9ZAUH+3E79/APGPi5sJ5qvr/cupcD3xRg/+8mG/vcZqSxS/8PgGbRIt7yZyhqi8kyj2FTdB27IL8tJ2F9N0GLJau7TXAUtKel3QyMXe0wO6EnLwicilmP8zzoUSDs7eqdrOsSClbF/am3bDCfrdS1Y8mN6rqT6Qz7DriVMLyMiKyNfA1bASwATaxsUdGvcuDLe5CLX57XiIip2M2x3ie1G+THgE4FbgiuOnE/Ug/D2R2/MB7MBvorCCMpwGX57Sx7L2IWFXMB7ZUwEPg7+EzgZafalp7Ip/bKrbEF8LxVSycNU6en+h9VA9nfRibQ3kUe2HlohZx9sXwKUTL+1h32z/uCfMpUSTeJzCzW16bPivtQVOnaXEKy8U1FrykqjMkZ4EDNX/eH2BrUi6DmXvSwufvJTumoTf6rVJjkzvTsM4St6V9l4zhMxbhsze2ZNBT2I3aIaPsMnmfgraVtXXNrnjOmQk5sn4jZs/CAgWOjH2fk7O/J7EH/DmKZ6wXwiaiHsEemFnA/4VtqUNzbMj/o1D+1vD/+hWuxQQsP8KDtBKkdNyXsvciVv5abKg4D5sHOBI4qqBO2VSRZ8X+/2DJ9jyOadaXxP6Pvv8rpXw0U39RuDZnhefiAcwPNe0YhR4TGfV+T+fs/mUp5T6XaFuh90A3/QN7afwMe5E8hLlTpno1YCaTX2H29J8Smycocd6/xEw8q4bPl7DFArLKz8AUw2VomSxOSCk3u0pfrfIZpAliC1W9oYt6y2Cx5Xtp+gqo99KeMT+OaopGFNPEt8H8Ly8iZ5ZbRA5X1eMqtPlqzEPipsT2TTGb0tYpdW4DNlDV50XkTiyE9JroNy0ZhlmibROwJOaPY9fsbm3F5GfVebeqnl+0LaXeepgW/DZs2PsTTIPZRzuHoN+hxL2Ila8c8JBhBsvdlvZ7xr63yftdO8PUP5hfvGOZJETka5hwnlPUnkS92ZoYwWVs21lVf53VNi0IrZWMVa97QUT+gAn1azCtc0tV3S2/1oK6S2MvqgWpBjDF5l8Z5WerJWTfH3ilqk5NM42IyEmq+snuzyqbQbqh3R2G36vSvqx0Zux++P0xbHh+asbvq3XRlvjw4SlatjEwYd720EfCV0KSjQT/xhZG/FVs22exzE1n0Qp1jZZqeQ/p/BS4Ogxfn8Zs4Yit8pyb7UxEdqW1qscMVU2u0hw/lxdF5HitsNIvFVy+RORyVd1BRG7BhPyZwOdVNRKqN4pIx0rYmOZReC9i/C+8TP4sIp/EtMjU4bjY6sFvA1ZK3MPJpK9d1w1fVtXtReTrmmOXjMgSZmKugql9RFU/LyIbheG7YqOGW9PKJnhRYmG8wUabpmntAfxaVc8WCxUulctARLbA7vMSwBSxXBMHqOonMsqvjY1ql1fV14YX9a6aHr25pLaS4dwlImXOFzA3MuBgEZkMvFji5TBJzP1xT3LMNZHwFYsyPA7LHb2TiLwa2EJVzyzbxo4GdFuxBL/ChMoVFC8rXRoRWVdV75T2ePQFpHVQVd1XLJT3a6r62ZRqWSyKzWzH1yG7HdhPRLZT1UPD/m8Skc0w29aHQtnbMVebtmVgYpyLrQywAu220gmYLTiVoBVtimmXAIeIyFaqmrfoYim7cZeCa9nw992aCDuOSNNgtHpuh0Mxv+mDsQjL7TBviDSqpopcOZyvxP6PtzUt3HmFoAXvKiIdcxd5glIscdG7Ma+DlehMlxiVOwITDtFLaZqInJ8huOJ8EcvSFWnhW2OTTUnimt4hWAL6MpyIRYdeDJZdLMxjZHE6pqScGsrPE5FzMb/hJIuKJUGKrudi8e8F1/V1mPa8TPj+CGZSui2jytHYSO1aVb1ZLGT6zznncRZmNoqE9Z8w75GuBfAgTRBzksPOPu33NFX9qLTHo0domtkiVvdKVc0KJEgrPx2zRT8fvk/CZkrfgk3Uvbpi8+P7jobUVds0DzNdvBi+T8RsVHkzyk9idvYXMG07y5tjfWwS8GjMPTDiSeCqtKGc2EKOn8k6dop5p+vcDqH+4pqRyyGl7GRs/bkXwveJ2NI7TyXK5ZkHUrVXsby++2HD3eTkXUc/FEvQ9C7MPWxtTOjupaor57S/ssdErO6ytNYyvEHT1+yrbHoJZW9U1c3iZg0JXiEZ5W9W1U0T5VPlQ8ZzHVH0fFfygqhKlfMoyyA14F+LyNtUNS/fbmW05W2wk3bmUU16WSSZIxY9dz7tbklZw96VMMEVmQQWx4YfL4jIArulZGSTIt9NZYJYasm1pbXC7gI0P7/vS7HlZsDy6+aiJT1GtGKO29jxdybDJk+nSaEbj4PKw97A5ZinSTQUXSxsa3sgyw69E3V+gUWAHaGqRXmowSagbsImhq5VVRVLGJ/HfXSfAPyFcMxFgVeLCBrmGGJ0o/lD+dzPEY+IyBqwYDn3PbBIyA5UdbuC88qjlBdED0rAf8UW6Y3OY3MqLo6QZJAC+BDgcBF5llZYcofW1QPXYz6eRdviLIN5Z8Tfonl2x+MxoT0D66RbA8eFm3pFrFw3IZfvwdIwTqIg1WOCrwKzg6YQtekLeRVERDAvk9VU9Zhgd1xBE5OGMXYUkWMwb4NJZGjMgb9qgV0/QVd2R6oPe8GCYBbYAVX1P2I+sm1Id2lRo372mzRzWMpQ+XDsnn8fOFcs5DmVmGBITQCeVS9Wf3/s+VsZW+9tcyxyNKk9xs1xVV6IH8OCN1bCvDguxwJFsjgQc61cV0QexNy6yqQu3ZLOOaSOycoYZVMBRC+LqiHMh2H9bw0RuQ6LzstyFy3FwEwQg0JEXoHd+B/TfhMnY9E+6/b5eCtgcfWChb7+vc/730lVf9dFmzYNbbpRU1INJsp/H3Nde5OqvkpstvhyVd00o/zdWDTU/DybcSi7YDhWsu1jMuwNv1+HRRreGr5vDJykiQlJ6S4taldD5WBnjJbEWQvzrf2lqv4pVqayx0TiGPOx/jFTVTcQ880/SlX3KqhX2rzTDUFxmaCqT5Yoew6Wc2EOrTkkzTNRSbsXBJgXxFFpprNuCWbIdbBn764KI8VUBqkBV5qtr8CO2ETXyrQnW3mSjAQ+sfasjPk8vgHTKK7FUlg+kCiXFAr3h7+vEJFXJLUb6YzKW/ATxVr/9WI5gaPrdDWWq7dtaCOdk49Rm1cUkRVTNK44m6nqRiIyGxYkHVk4p/z92IKaZd7O+5Qo0w+qDnvBJu7OF5HopbkCFlHVRpqALaLbobLaROWxwLFik0bvxTJqrRErU9ljIsH/VPV/IoKILBL6zTpZhauad5KmikCadxDhuB/FJrPBlvg6Lf7CyWATzO+5sA8G0+PHsCxy84FP5wlGaU/i1UFyxCPtAWVx1g6mncxkTUUMTABLd7P1ZVgWC9iIhLliwQXXqmracCPONMz74N3h+/vDtrckyn0r/F0U6whzMWG6Hrb6b9vSK2VtrBn8EHM63zN83ye0KXnTD8M68rfoROkcXsZ5LkxARbar5ciP1voc8FuxWfTcdec0zDBL+dDibu2OVYe9qM1sr0tLY7mz4MGstLxQrN5rU+oUaamTMVe6b5KTtU1KekwkeEBs4cuLgN+LyL8wz5AsTqSaeaeUd1AQ7Bdi3g+nYfdgQ2xNw91UdWbOMW7D/MSLFsoE8954DvO62gl4FfbyzWILTMn4KfY850bfkh8Fl2fCLGSQXhCVZ+tL7ndqyuZlsA50pKp2LC0Tq9sxY5k3iynmXnSstpZSeS3wGVX9UEEbX077w/i3nLKl2yTmB7uFql6Xd/yUentjmt9GWGfdAzhCVc/LKH85NnE1n5ig1pzlkILZokxKw8oeB90S7L2HYRntPhIE7DpZIzERuZbW8kK7EJYXUtW0PhfVmYpl53s1Ft69E6YMpNoGReQAzMvkaVqjJo0LeenCYyKnfdtgE6WXasZyT1XNO1LSO0hEfgd8XVVnpLTp86q6U067r8I8cm6iXQlIs8fHg3MmYabCTNNWkEVvwV5q6wG/wRbjzFy5ZlAM1ARBxdn6MmQJAbEIuitIWdsrxiMi8n5aCT7eS34O4XUj4RuOfZvYMjqpBJPLt7B8vg9jk1h30MrpmsbTYWQQrZP3Buzh7EAtqOKb2Bu8NGo5KW7BQnkFeGeBoFxGVXfI+T2NUsvGRwJWMqLtkuUlY6Y6tr88t7VpmB9wdL0ewLS2LFPYYqp6pYiI2nI8R4pFZmUKYOxltj6mXOwr5qyftXovmMveazTFLSxGNx4T0TOQJOq/S9B6FpNUNe+U8g7CVo6ZkaysqleLJbDK48iC3+MsGNWoRZbmFlZzS7wUyw++CCYHZojI0aqam9NXRN5O5zJrR1doaxuDFMDHUXG2vhdU9TEpuvKWTPkkWgv1XRe2ZXGHiJyBTfgpZrLI65jHYDPOV6iFOG6H3dw8Pg6cLSJLYdfpMbIDDKBaMh7AJjRUdR9sRY/ktjSuEJEdVPXyMvsPVE1mXjbaLj5TfRT5wjDJGqq6l1gSf1T16YI+UjraLsbT4cX4fDArPEzOgqeYG1luKDgVPCYSRAlyslwCs9pV1bxT1jsob7KtaLJvFq1ruzZm8siarF5fRJ4I/wsWvPEEOXMwQfC+HXs+V8XyX+SaEkTkB1gw0HbYS3YPihf2zWUgJojQiffAbDKlZ+t7POabsLyqebbQqvtcFBOQkT3sGuD7mp3Wb5aqbiKWtm/D0HluUtXXlzjWZABVfaKgXKmgikSdNm+DMATLDCSJHeMZTLsoc4xpKZtVO1MaRtF2e2JRRBGTsUmXzGsl1T0urse0/uvUJiHXwIaaqccQy91xBzZyOwYbtR2fZ6sUkVNoCcxPY6abOZoR6ScW1TUNsz3GX1RpKS8LPSaGhZTwDhKRh0kfkQqwp6oun7P/W7BFc5fG1l+bBTylqoXuayXafjaWO/h3WK6NrEi5ZL15qrpe7O8SmCJUdbTY2ucAbcDXaEoSmj7sNy3oYRlskuEDqnpnZ60FdVenxMq9PbTtCsy396vYZOHDwKaaE4kTNN+pFHhBdNmeL2DCYTFaWpdgS/+crr1PiHbTpsrRdrG6pd3WQvm3YMP4V2Na3RuwFUJmVG95qeOtii0pPy+nzE2Y903Svl6U+CbymNhLVdfIKxvK74ZNFivwB1W9KKdsaa+GWJ2lsZdCfCh+TaJM1/b+6F6LyEGYaej4rLmRqojlIY808LgsyVU0Yrbymdgk+WOYIpO6gnWptgxQAB+BaWg/pz3qLMsOVXa/qyQ2KfColvBfDBfuZFo24PdgfqKbJcplRbbZAbMTTy+OnfMEzEd5KeAnqpppZxaRC7AZ36gz7oOl90t1fQlD6CpBFYjIV1W1tPkn2KHnqOp/g818I2yhy47JROkyqki6S7BeSQCHOi+jFZI7M8/2GsxlaeeQlpUvtx2a4RYoItfnvZATZRencxieOZkWq3cK5pIVT2b+F1VNNSsEe2yaV8MrseWkDk2UTw306PPoczaWW+Xb2IINt0tssm0YBJn2PczjKFpL7gxVPaLrfQ5QAKe5hKkWuPQMkugNltg2U1U3T2xLCvk2wgRNct8TsZyruasVpNSr6plRKagi1NlPYxmbQlu/pNkTmvOwiaX1sKiiM7ElajoCFqTLlIYisjM2zM+NtpN2H+uX0K7JZ9n3uhWOG8e+LooJoudVNbn4aiSsIzamPemPZgkjETkWW/XkEtpNEB2KScYw/L+q+v70M1tQ73bgtdEcQTAJzlfV1MlgqZjzREoGekgXEYaxultjE5bXqerXw+j10KwX+iCR9NVr3o/NqRzZi1I5iBUxdlPVC1V1NRFZpleNt09timaHU1fuTZbPELDLYpp2aodSmwF+SkSWqmg+KO0FEagaVAGwvdjE3X6YaeSHmKkji+dVVUXkHcB3VPXMnOFkL6HFhdF22p2PdZqv9IJdkuEzraq3JDZdJ62MYsmyCwIxgm26bGDG+8Lf+Igka4JMVPUpEdkP+F40DC9xjLuAKZigB9NkM80ilPdqiCgb6BH5N++G+fT+OHx/L5bnIpNgzrgGFpg77h2G8A10u3pNIYPwgvgSrdnEK8jPzTBWJGeHD4j9ppgmtgCxJBtfw2w8x2Ba4LJYAp0PqOqlGcf5HzBfLHY/bnbJ6zhVvSCqBlWgqu8Tkb0wu+NTwHs135f4yWA/fj+wdTjeQhllu01pWCXarhIVhGEb0u7GNQHTbF9R5pBlj6HV8lmLWDDD3tjLE2zl3iJehnnwRGapTYEbJESApWieZb0aIkoFemiIMBSRY7R9PugSEUkmBiKU/TJwXhDqi2ATZRsAz4vI+1Q1rT2DZmJMkdwLWx7pAuCCki/ETAYhgCXj/6FRsdODuaodjtlwp2OZ12aGodZPMR/CNH5DikZd0LY5mBtNNJR+irAAYUaV72KO+S8Pw9k9sGVYMhELQDgEuACLEtonaG1Z7lB7YZrafqr6TxGZgq0g209KR9tVJbJLh//b/I1F5DhVzQpZj2vAz2OJXPbLKNtt2xai3bNmBnBqhj38UExT/mWwga4O5OWgiPhycZEWYYTzW1peDYdry6uhI3+2qkY+yUcGU8xSZD8TAMuJyOoaJrtFZDUskU0ae9FSiD6IvQiXwwJSzib9hTBoJorIpGCi2Z723Mo9ydC+24DFltd5L3bhfow9yAsEcZb9bayQEhmW4jZYEblDY/lXpcAVSixn6xRVvaugHZMxX8uVsOT1V4Tvn8HWi3tHTt11aQVVXKnF0Wd3AgdqCDLAosM+nGUTTNTNNb1Iy9VIsIenze0oS/uXLqLtyiI5CX+S33s4RjTpWPW8z8BGE/FJ1xdUdf9e25Q4zirAWqp6ReiTkzQnCY6U8GoI5SZgqxOXXjJLRN6KDdUjb6NVsSW4OvzMpT0a7wJsfuPU8L0v964qIvJFzHXyEcy0s1Ew0a0JnK2qaSu+lGIQGvA/gEiL+WfsfyjOWTBQJCPDEpZFP058SJ+0x2a+sURkF8KCl8BqYlFzR2dMNpwD/AtzhfsIphEujEWpzck7B60WVAHweg3+xUGQfktSEpJ0aXrpNqVhN9F2ZckbhaWOysT8Wg/EXNbAzuVUzfZgmZXxfxGbanuI73Qxv/G0Nm2CjcRWpV1hyA3nF5GPYFraMlh/Xxlb/Tc18b+UT18ZRWPOldiSR0Wo6qVhFBYl5LlTW0tWJXlGLOT/IWA72pP9d6QSHQtU9VgRqbx6TdmdD+SD5WIt3DaWH8zJXkqUe4HWisPPh/+j78/l1LsFG47Njm2bn1F2fuz/iZgwXrJE225NfJ8I/DGj7Odi/7878dtxKeVnYWu0vTu0Z/OwfV0KVoZN7j9rW+y3r5Gx8nUf7vOtaf+nfQ/btsFs0kdjyxi9A4u6mwusBpzTx/O+FYvQi76vntam8NtdoT2rYd4iq2B5LYrOfw72Mi/sh9FvmOY7J3a/f55Tfnp4Fq6ktRr0xTnlF8LCm38RPp8EFsoouzmmXDyK5SuJtr8NC6Lpe38Z5mdwO07v6KkdbcxO1vwcVxjg/m8Mf2fHts0rc32Krg1mC0x7ITyKrXWXe4ySgmhO7P87Er/NLmhfpfsd2v4iNsKIzuWJPt2HSi9QLJx0w5TtG4R6Z/fxvLfHlkCfgXmi3Adsl1H22n70Q0x7Tu2H4febo/uPLdnU1hdSym+T9skpfwZmcnlT+EzD/Gezym+GjRTARiSHAW/rR9+o22cQbmhRwvS2xfSwUNOhDCFi/ohLAn8Ms8O5GZa65DYReR9mtF8Le+tfn1G2Uvy6qn4V+KpUC6qoOhSvbHqRLlcg1t5SeOaiqmU8BeIsoaqzU/YzR0QewrKitdHDeV8Z+kY8RWbWcHxqsBlfSbn8GhFXi61IvphYNOAnML/jLCqlr9Tq+ZOrmF2mYhnlJgVvos2wl9XnRWRDVT224rFrzSBswPGE6XH7b2HC9AGSmW+1zxyErZj6DJZ3+DLSV37tRkhE3B3/IvlBFZrxf9p3aL0U4i8Ewves9faqrkActbt0tN0YICKytCbCoINb2vMaUqom6Pa8F8LcIBd4QYhIlhfEvpg5YCFaL0elOP/s/wP2x0wLB2BpMjMztGlFr4YwV/A9zKNmYcwM9t+k0hDjBRFZQ1X/EuqvTvZK6XtgI49FsDmklVX1CRH5BpY/Y1wJ4IGp1sDuw1bvx/pDyjB2AMc4F3ugVgBeB9wMfDOjbFe27C7blWrTyyk/DxPs64f/DwGuHtJ9+2i4jttgo6QlsRy/N2Kz9f0879LDcXLstjn7n4D5Vw+kfKgzCwt1no0J331JmVOIla9idpmd9n/4PmcY/WOgfW9gO7aMUieEmzULi05aaqgnG+yMic/9mF/t6n3Y/1XYBMIxWM7XQZ3HXphLzN+ANwy7E4U27RweyMcoYdMl2Ekxn9X94tuG2P5rMJv6o+H/XQZw3nPLbAvbT8cyxFU9l59grpCDKj8r/J0X23Z9QZ1FsKCd9Ql25oxyNwIvCf9PiG1fapj9Y1CfQeYDPpNyS+2MJSdgQ8dzMe3rPVik011YeO62vexcVbcLNvA9gdOCr+/PVTXVDNENXQRVjBUnUnIhz0CVaLuBo5bP4grNSDWaw4lUO+8qw/GtgA+K5VV5htb8QNGqMitgqynfRHtEZtZcR9XyT4mFv88VkeMx19OO5d8jKppdttZgE9d2089C5EeINpJBJuOZoxWSzIwFkpOMRwpW2O3iWK/DfHv3UtWiXA1V9tt1UMUgCbbD7TXdXppW/hVYkM7NqvoHsWi7bbVgLbVBIras0kNYHutrsEQwuXk9ujjvNwFnYUEJgrmW7auqV6WUXSVtH5qSqyRRb5uMeqmTZ12UXwW7Tgtj9u7JWJ7suzPKj0nwSRMZpAZcNcnMWPCiiOyJ+SJCexKNnt9EIvIqzDywBzaM/TmWpLuflAqqGAKVQovVMkudAAui7e4fpvANbVozvAjeiJkWThGRxwuUhtLnHbT89bGIs0IviKSgDZ4KB1IwEZUlOHstL5acaWVVPTl8vxpbMUSxwI1UAUwFL4hRY8IA9/0x4GQRuU9E7sPyKxyQX2Xg7I29fR/G3uD7AO8PoZqf7MP+z8KGkx8HdlTVU1T14T7sFxH5HNiKGdK5dlrq6gtjzLFYHotFaU1kdbiaicjmIjJDRC4UkQ1F5DbMVPWQWMjq0BCRlbGk7W/EVu+9nfZVO9Iodd6wYC2yXVX1GVWdp6pz04SviLxSRE4TkV+LyP4i8hIR+RbwJ3KWSBJbVBQReVJEnoh9nox5tKTV21xEbhaR/4jIsyLyQkb5zxFWTg4sgiUs2hbr81m8ILYaSXS8PLPLaDFoIzM2PJkc/j902EbvAZ3jJCyj1CNYpNNs4P/Ctkqz5DnHqBRUMYRrMKtsObqMthuDc3gRmwR6R7/PO1b+WEwZeSPmercRllsgXuYqbFHKHbGE5POwJFCvKNj3Kt3eO0p4NRACNmLfT4r9PzOl/KFYJrYdsNSYM8LnPiyf9VD7bB0+A7MBpyEif1PVKWN2wNZxu1q1ocL+v41pPZ/SkPAkTMB9E1vR4JBe9h/2N1tbSUoW/J/2fRiIyNeA6VqwkKf0kOho0Igtl7QVNlk0Bfgz5hp3Zk6dUucdK99h6yWRwD05HyEWDDJFswM2onLxJEQXqOruJdsUrWU4T8MEn6Ss3CEid6vqmhn7+IsmlkoSW8F7S2yy+E/YIqe3ANM0ZQ25UWTQy9InGVZ6yihbWJWkKVXYGVhbY28zNVPBxzG3tJ4FMNWDKsaaA4HPiSXwzlvIs6tER2OBqs4Vkb9gKxe/keChgXn0ZFH2vKNjlMpVLJadLHpe/gm8RCw/L5q9yEH8+aqy8kxZr4YbReQjqnp6oq0HkLI6sKp+Jvy+MLAJJoy3AA4MtvXURWFHibEWwEN5wFT1kvD3bAARWVxLrCFX7RCdQwm1FQX6dc7dRKmNGVo+tLi25yEiszC75vXYwplba4HHQdnzFpHDCvYTn7RbCtMU4wI1SuOqZAvXvJd0Hvtg80EHYl4NK2PLMSX5FHCRWLh91J6NsWv2zpz9L4aZIpcKn79jUXojzyByQcTX8Gr7CbsRQ0NsdYEzgSWAKWHIeYCqfqLHXf9RLF1jMq9wtG5Uz2j3octjgpQMLa75eeykqv9XpULZ86Y1MbcOZheNJrN2ISy9E6Gqq1ZteCDv5dahlVf1alCbUN4yuNJFbo+/UdXpaY0RW+zzNVhwyo3Yi+0EzVn5etQYUxvwsBGRGzEXsYtj9tTbtEJy6Yz9roTF5z9Na/mjTbEXzrtU9cGeGt4ApMJCnnVFbFmoqbQCBq7G8jln+gJXPW+xRPS7x+YKlgTOV9UODxARuVJVty/a1i0ich3wHlW9P3yfg4VHL4HZaXs6johciuWTvg0TvjcwoGWomspYmyCGjqreL9Jmiu7ZHSYI2M1imoEAv1PVK3vdd4OospBnXfkh1aM3q573FCC+rPyzWML1BYjIopgNdtmELXgysGLJcynDwpHwDVwb7MuPRfbmXlDVt4o9bK/B7L+fBl4rIo9hy9hP7fUYTWfUBPD9YksSaZgYOJjWBF3PhKFY6nBsBKhVaHGXrJHwHDhKihddrHre5wA3icgvsZHSu+hckeUAzIVrRVq2VrBcEycXnUQFlo5/UdW4L3zWmm2VCNrubSLyOLbq8r+xSevXY6ONkWaQgRh15GO01mF7AEt7d+AwGzSO2AuLBNtPLcptJfq/kOegeVpEtoq+SLnozUrnrZbPdl/MB/pxLAz5uESZ76gtJPsZVV0t9llfVU/q5sQyuFFs+aI2srwaqiIiB4vIz0TkfszOvTOWd2U3bLmkkWekbMDO2CAFC3nWlTAp+yNsph5MSH5QVbNWqE7WL3XeQcivparTRGQ5LCH8vSnlFsaUhjIrKFdGRF6OJWF/hhSvBlV9qMf9n4DZfq9T1X/0sq/xykgIYBHJW6ZbVfWYnN+dHCRnIU8gayHPWhOCaCJf7kNV9cSUMl2dt9iKD5sA66jq2iKyIjYJ17GyrozdCspxr4bbs7wanP4zKgI4LSHO4sB+wMtUdYkxbtK4IfjOHo5pjadhrlwzRWRdbBHFoUbo9UpW9Ga35x1syhti4eORJ86CCLTwfZKqPp+MiAu/9TVrnzNcRmISTlW/Ff0f3H4OwexwP8MSxTvdM0lDGK6IHK2qMwFU9c6Et0lTyTqJbs/72eA1oaFumrfBTZg/cZXcwU4DGQkBDETrex2GZUQ7G0uA4g7hvVPb0OI+kXUO3Z73eSJyKvDSMAH2YWzliziRBP8McJWI3BO+r0o9Mt85fWJUTBDfwGZeTwNOVtX/DLlJ4wYReQFbRSGKdIxW5hBgUVWtvStaUfSmqnYoKr2ct9hKxTuEspep6u8Tvz9Aa0HbxQiLXmKh2k9rRo5lp3mMigB+EZvpfZ72By03cYrjDJIsrwkR+QfwfTLMH5q+ArbTQEZCADvOsKniNSGxtJLO+GZkbMCOM2ROouU1MZ2E1wQQd1sbF7OXTjGuATvOGCAVEtGLyDKanfPXGUeMWiiy4wyL0l4TLnxHB9eAHWcMGA/eIk7/cQHsOI4zJNwE4TiOMyRcADuO4wwJF8CO4zhDwgWw4zjOkHAB7DiOMyT+P9+g+f/WkAPAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualising the missing values\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be removing the column/feature that has almost missing values as compared to total no. of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing of Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LotFrontage Column\n",
    "df['LotFrontage'].fillna(df['LotFrontage'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TA'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BsmtQual'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtQual Column\n",
    "df['BsmtQual'].fillna(df['BsmtQual'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtCond Column\n",
    "df['BsmtCond'].fillna(df['BsmtCond'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtExposure Column\n",
    "df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtFinType1 Column\n",
    "df['BsmtFinType1'].fillna(df['BsmtFinType1'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtFinType2 Column\n",
    "df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Electrical Column\n",
    "df['Electrical'].fillna(df['Electrical'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FireplaceQu Column\n",
    "df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageType Column\n",
    "df['GarageType'].fillna(df['GarageType'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageFinish Column\n",
    "df['GarageFinish'].fillna(df['GarageFinish'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageQual Column\n",
    "df['GarageQual'].fillna(df['GarageQual'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageCond Column\n",
    "df['GarageCond'].fillna(df['GarageCond'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MasVnrType Column\n",
    "df['MasVnrType'].fillna(df['MasVnrType'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MasVnrArea Column\n",
    "df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dropping Columns\n",
    "df.drop(['Alley','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0\n",
       "MSSubClass        0\n",
       "MSZoning          0\n",
       "LotFrontage       0\n",
       "LotArea           0\n",
       "Street            0\n",
       "LotShape          0\n",
       "LandContour       0\n",
       "Utilities         0\n",
       "LotConfig         0\n",
       "LandSlope         0\n",
       "Neighborhood      0\n",
       "Condition1        0\n",
       "Condition2        0\n",
       "BldgType          0\n",
       "HouseStyle        0\n",
       "OverallQual       0\n",
       "OverallCond       0\n",
       "YearBuilt         0\n",
       "YearRemodAdd      0\n",
       "RoofStyle         0\n",
       "RoofMatl          0\n",
       "Exterior1st       0\n",
       "Exterior2nd       0\n",
       "MasVnrType        0\n",
       "MasVnrArea        0\n",
       "ExterQual         0\n",
       "ExterCond         0\n",
       "Foundation        0\n",
       "BsmtQual          0\n",
       "BsmtCond          0\n",
       "BsmtExposure      0\n",
       "BsmtFinType1      0\n",
       "BsmtFinSF1        0\n",
       "BsmtFinType2      0\n",
       "BsmtFinSF2        0\n",
       "BsmtUnfSF         0\n",
       "TotalBsmtSF       0\n",
       "Heating           0\n",
       "HeatingQC         0\n",
       "CentralAir        0\n",
       "Electrical        0\n",
       "1stFlrSF          0\n",
       "2ndFlrSF          0\n",
       "LowQualFinSF      0\n",
       "GrLivArea         0\n",
       "BsmtFullBath      0\n",
       "BsmtHalfBath      0\n",
       "FullBath          0\n",
       "HalfBath          0\n",
       "BedroomAbvGr      0\n",
       "KitchenAbvGr      0\n",
       "KitchenQual       0\n",
       "TotRmsAbvGrd      0\n",
       "Functional        0\n",
       "Fireplaces        0\n",
       "FireplaceQu       0\n",
       "GarageType        0\n",
       "GarageYrBlt      81\n",
       "GarageFinish      0\n",
       "GarageCars        0\n",
       "GarageArea        0\n",
       "GarageQual        0\n",
       "GarageCond        0\n",
       "PavedDrive        0\n",
       "WoodDeckSF        0\n",
       "OpenPorchSF       0\n",
       "EnclosedPorch     0\n",
       "3SsnPorch         0\n",
       "ScreenPorch       0\n",
       "PoolArea          0\n",
       "MiscVal           0\n",
       "MoSold            0\n",
       "YrSold            0\n",
       "SaleType          0\n",
       "SaleCondition     0\n",
       "SalePrice         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking again\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 77)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Again visualisation\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing ID and GarageYrBlt (Year Column)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id','GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 75)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing of Testing Data\n",
    "\n",
    "### Filling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1459 entries, 0 to 1458\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1459 non-null   int64  \n",
      " 1   MSSubClass     1459 non-null   int64  \n",
      " 2   MSZoning       1455 non-null   object \n",
      " 3   LotFrontage    1232 non-null   float64\n",
      " 4   LotArea        1459 non-null   int64  \n",
      " 5   Street         1459 non-null   object \n",
      " 6   Alley          107 non-null    object \n",
      " 7   LotShape       1459 non-null   object \n",
      " 8   LandContour    1459 non-null   object \n",
      " 9   Utilities      1457 non-null   object \n",
      " 10  LotConfig      1459 non-null   object \n",
      " 11  LandSlope      1459 non-null   object \n",
      " 12  Neighborhood   1459 non-null   object \n",
      " 13  Condition1     1459 non-null   object \n",
      " 14  Condition2     1459 non-null   object \n",
      " 15  BldgType       1459 non-null   object \n",
      " 16  HouseStyle     1459 non-null   object \n",
      " 17  OverallQual    1459 non-null   int64  \n",
      " 18  OverallCond    1459 non-null   int64  \n",
      " 19  YearBuilt      1459 non-null   int64  \n",
      " 20  YearRemodAdd   1459 non-null   int64  \n",
      " 21  RoofStyle      1459 non-null   object \n",
      " 22  RoofMatl       1459 non-null   object \n",
      " 23  Exterior1st    1458 non-null   object \n",
      " 24  Exterior2nd    1458 non-null   object \n",
      " 25  MasVnrType     1443 non-null   object \n",
      " 26  MasVnrArea     1444 non-null   float64\n",
      " 27  ExterQual      1459 non-null   object \n",
      " 28  ExterCond      1459 non-null   object \n",
      " 29  Foundation     1459 non-null   object \n",
      " 30  BsmtQual       1415 non-null   object \n",
      " 31  BsmtCond       1414 non-null   object \n",
      " 32  BsmtExposure   1415 non-null   object \n",
      " 33  BsmtFinType1   1417 non-null   object \n",
      " 34  BsmtFinSF1     1458 non-null   float64\n",
      " 35  BsmtFinType2   1417 non-null   object \n",
      " 36  BsmtFinSF2     1458 non-null   float64\n",
      " 37  BsmtUnfSF      1458 non-null   float64\n",
      " 38  TotalBsmtSF    1458 non-null   float64\n",
      " 39  Heating        1459 non-null   object \n",
      " 40  HeatingQC      1459 non-null   object \n",
      " 41  CentralAir     1459 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1459 non-null   int64  \n",
      " 44  2ndFlrSF       1459 non-null   int64  \n",
      " 45  LowQualFinSF   1459 non-null   int64  \n",
      " 46  GrLivArea      1459 non-null   int64  \n",
      " 47  BsmtFullBath   1457 non-null   float64\n",
      " 48  BsmtHalfBath   1457 non-null   float64\n",
      " 49  FullBath       1459 non-null   int64  \n",
      " 50  HalfBath       1459 non-null   int64  \n",
      " 51  BedroomAbvGr   1459 non-null   int64  \n",
      " 52  KitchenAbvGr   1459 non-null   int64  \n",
      " 53  KitchenQual    1458 non-null   object \n",
      " 54  TotRmsAbvGrd   1459 non-null   int64  \n",
      " 55  Functional     1457 non-null   object \n",
      " 56  Fireplaces     1459 non-null   int64  \n",
      " 57  FireplaceQu    729 non-null    object \n",
      " 58  GarageType     1383 non-null   object \n",
      " 59  GarageYrBlt    1381 non-null   float64\n",
      " 60  GarageFinish   1381 non-null   object \n",
      " 61  GarageCars     1458 non-null   float64\n",
      " 62  GarageArea     1458 non-null   float64\n",
      " 63  GarageQual     1381 non-null   object \n",
      " 64  GarageCond     1381 non-null   object \n",
      " 65  PavedDrive     1459 non-null   object \n",
      " 66  WoodDeckSF     1459 non-null   int64  \n",
      " 67  OpenPorchSF    1459 non-null   int64  \n",
      " 68  EnclosedPorch  1459 non-null   int64  \n",
      " 69  3SsnPorch      1459 non-null   int64  \n",
      " 70  ScreenPorch    1459 non-null   int64  \n",
      " 71  PoolArea       1459 non-null   int64  \n",
      " 72  PoolQC         3 non-null      object \n",
      " 73  Fence          290 non-null    object \n",
      " 74  MiscFeature    51 non-null     object \n",
      " 75  MiscVal        1459 non-null   int64  \n",
      " 76  MoSold         1459 non-null   int64  \n",
      " 77  YrSold         1459 non-null   int64  \n",
      " 78  SaleType       1458 non-null   object \n",
      " 79  SaleCondition  1459 non-null   object \n",
      "dtypes: float64(11), int64(26), object(43)\n",
      "memory usage: 912.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            4\n",
       "LotFrontage       227\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1352\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           2\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         1\n",
       "Exterior2nd         1\n",
       "MasVnrType         16\n",
       "MasVnrArea         15\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "BsmtQual           44\n",
       "BsmtCond           45\n",
       "BsmtExposure       44\n",
       "BsmtFinType1       42\n",
       "BsmtFinSF1          1\n",
       "BsmtFinType2       42\n",
       "BsmtFinSF2          1\n",
       "BsmtUnfSF           1\n",
       "TotalBsmtSF         1\n",
       "Heating             0\n",
       "HeatingQC           0\n",
       "CentralAir          0\n",
       "Electrical          0\n",
       "1stFlrSF            0\n",
       "2ndFlrSF            0\n",
       "LowQualFinSF        0\n",
       "GrLivArea           0\n",
       "BsmtFullBath        2\n",
       "BsmtHalfBath        2\n",
       "FullBath            0\n",
       "HalfBath            0\n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         1\n",
       "TotRmsAbvGrd        0\n",
       "Functional          2\n",
       "Fireplaces          0\n",
       "FireplaceQu       730\n",
       "GarageType         76\n",
       "GarageYrBlt        78\n",
       "GarageFinish       78\n",
       "GarageCars          1\n",
       "GarageArea          1\n",
       "GarageQual         78\n",
       "GarageCond         78\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1456\n",
       "Fence            1169\n",
       "MiscFeature      1408\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            1\n",
       "SaleCondition       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Has some different columns missing that were not there in Training data\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSZoning Column\n",
    "df_test['MSZoning'].fillna(df_test['MSZoning'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LotFrontage Column\n",
    "df_test['LotFrontage'].fillna(df_test['LotFrontage'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilities Column\n",
    "df_test['Utilities'].fillna(df_test['Utilities'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exterior1st Column\n",
    "df_test['Exterior1st'].fillna(df_test['Exterior1st'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exterior2nd Column\n",
    "df_test['Exterior2nd'].fillna(df_test['Exterior2nd'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MasVnrType Column\n",
    "df_test['MasVnrType'].fillna(df_test['MasVnrType'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MasVnrArea Column\n",
    "df_test['MasVnrArea'].fillna(df_test['MasVnrArea'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TA'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['BsmtQual'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtQual Column\n",
    "df_test['BsmtQual'].fillna(df_test['BsmtQual'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtCond Column\n",
    "df_test['BsmtCond'].fillna(df_test['BsmtCond'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtExposure Column\n",
    "df_test['BsmtExposure'].fillna(df_test['BsmtExposure'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtFinType1 Column\n",
    "df_test['BsmtFinType1'].fillna(df_test['BsmtFinType1'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtFinSF1 Column\n",
    "df_test['BsmtFinSF1'].fillna(df_test['BsmtFinSF1'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtFinType2 Column\n",
    "df_test['BsmtFinType2'].fillna(df_test['BsmtFinType2'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtFinSF2 Column\n",
    "df_test['BsmtFinSF2'].fillna(df_test['BsmtFinSF2'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtUnfSF Column\n",
    "df_test['BsmtUnfSF'].fillna(df_test['BsmtUnfSF'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TotalBsmtSF Column\n",
    "df_test['TotalBsmtSF'].fillna(df_test['TotalBsmtSF'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtFullBath Column\n",
    "df_test['BsmtFullBath'].fillna(df_test['BsmtFullBath'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsmtHalfBath Column\n",
    "df_test['BsmtHalfBath'].fillna(df_test['BsmtHalfBath'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KitchenQual Column\n",
    "df_test['KitchenQual'].fillna(df_test['KitchenQual'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functional Column\n",
    "df_test['Functional'].fillna(df_test['Functional'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FireplaceQu Column\n",
    "df_test['FireplaceQu'].fillna(df_test['FireplaceQu'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageType Column\n",
    "df_test['GarageType'].fillna(df_test['GarageType'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageFinish Column\n",
    "df_test['GarageFinish'].fillna(df_test['GarageFinish'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageCars Column\n",
    "df_test['GarageCars'].fillna(df_test['GarageCars'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageArea Column\n",
    "df_test['GarageArea'].fillna(df_test['GarageArea'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageQual Column\n",
    "df_test['GarageQual'].fillna(df_test['GarageQual'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GarageCond Column\n",
    "df_test['GarageCond'].fillna(df_test['GarageCond'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SaleType Column\n",
    "df_test['SaleType'].fillna(df_test['SaleType'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dropping Columns\n",
    "df_test.drop(['Alley','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0\n",
       "MSSubClass        0\n",
       "MSZoning          0\n",
       "LotFrontage       0\n",
       "LotArea           0\n",
       "Street            0\n",
       "LotShape          0\n",
       "LandContour       0\n",
       "Utilities         0\n",
       "LotConfig         0\n",
       "LandSlope         0\n",
       "Neighborhood      0\n",
       "Condition1        0\n",
       "Condition2        0\n",
       "BldgType          0\n",
       "HouseStyle        0\n",
       "OverallQual       0\n",
       "OverallCond       0\n",
       "YearBuilt         0\n",
       "YearRemodAdd      0\n",
       "RoofStyle         0\n",
       "RoofMatl          0\n",
       "Exterior1st       0\n",
       "Exterior2nd       0\n",
       "MasVnrType        0\n",
       "MasVnrArea        0\n",
       "ExterQual         0\n",
       "ExterCond         0\n",
       "Foundation        0\n",
       "BsmtQual          0\n",
       "BsmtCond          0\n",
       "BsmtExposure      0\n",
       "BsmtFinType1      0\n",
       "BsmtFinSF1        0\n",
       "BsmtFinType2      0\n",
       "BsmtFinSF2        0\n",
       "BsmtUnfSF         0\n",
       "TotalBsmtSF       0\n",
       "Heating           0\n",
       "HeatingQC         0\n",
       "CentralAir        0\n",
       "Electrical        0\n",
       "1stFlrSF          0\n",
       "2ndFlrSF          0\n",
       "LowQualFinSF      0\n",
       "GrLivArea         0\n",
       "BsmtFullBath      0\n",
       "BsmtHalfBath      0\n",
       "FullBath          0\n",
       "HalfBath          0\n",
       "BedroomAbvGr      0\n",
       "KitchenAbvGr      0\n",
       "KitchenQual       0\n",
       "TotRmsAbvGrd      0\n",
       "Functional        0\n",
       "Fireplaces        0\n",
       "FireplaceQu       0\n",
       "GarageType        0\n",
       "GarageYrBlt      78\n",
       "GarageFinish      0\n",
       "GarageCars        0\n",
       "GarageArea        0\n",
       "GarageQual        0\n",
       "GarageCond        0\n",
       "PavedDrive        0\n",
       "WoodDeckSF        0\n",
       "OpenPorchSF       0\n",
       "EnclosedPorch     0\n",
       "3SsnPorch         0\n",
       "ScreenPorch       0\n",
       "PoolArea          0\n",
       "MiscVal           0\n",
       "MoSold            0\n",
       "YrSold            0\n",
       "SaleType          0\n",
       "SaleCondition     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking again\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing ID and GarageYrBlt (Year Column)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['Id','GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data as well as Testing data is preprocessed, Now moving to further operation of Handling Categorical fatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "#List of categorical variables\n",
    "cat_columns=[]\n",
    "\n",
    "for i in df.columns.values:\n",
    "    if df[i].dtypes == 'O':\n",
    "        cat_columns.append(i)\n",
    "        \n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of Categorical variables\n",
    "len(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilities\n",
      "Condition2\n",
      "HouseStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "Heating\n",
      "Electrical\n",
      "GarageQual\n"
     ]
    }
   ],
   "source": [
    "#Difference in categories in Columns of Training and Testing dataset\n",
    "for i in cat_columns:\n",
    "    if len(df[i].value_counts()) < len(df_test[i].value_counts()):\n",
    "        print(i)\n",
    "    elif len(df[i].value_counts()) > len(df_test[i].value_counts()):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AllPub    1459\n",
       "NoSeWa       1\n",
       "Name: Utilities, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example\n",
    "df['Utilities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AllPub    1459\n",
       "Name: Utilities, dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Utilities'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that there are several columns which have more categories either in training data or testing data and due to which if we convert training or testing data alone, all the categories will not be considered leading to mismatch of columns while doing OneHotEnconding\n",
    "\n",
    "To arrive to solution, we can concat both training and testing and due to this all the categories will be covered leaving no category either in training or testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging training data and testing data via rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df,df_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 75)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_copy = data.copy()\n",
    "for i in cat_columns:\n",
    "    abc = pd.get_dummies(final_df_copy[i],drop_first=True)\n",
    "    final_df_copy.drop([i],axis=1,inplace=True)\n",
    "    final_df_copy = pd.concat([final_df_copy,abc],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 236)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>AdjLand</th>\n",
       "      <th>Alloca</th>\n",
       "      <th>Family</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          2003       196.0         706           0        150          856   \n",
       "1          1976         0.0         978           0        284         1262   \n",
       "2          2002       162.0         486           0        434          920   \n",
       "3          1970         0.0         216           0        540          756   \n",
       "4          2000       350.0         655           0        490         1145   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  \\\n",
       "0       856       854             0       1710             1             0   \n",
       "1      1262         0             0       1262             0             1   \n",
       "2       920       866             0       1786             1             0   \n",
       "3       961       756             0       1717             1             0   \n",
       "4      1145      1053             0       2198             1             0   \n",
       "\n",
       "   FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd  Fireplaces  \\\n",
       "0         2         1             3             1             8           0   \n",
       "1         2         0             3             1             6           1   \n",
       "2         2         1             3             1             6           1   \n",
       "3         1         0             3             1             7           1   \n",
       "4         2         1             4             1             9           1   \n",
       "\n",
       "   GarageCars  GarageArea  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0           2         548           0           61              0          0   \n",
       "1           2         460         298            0              0          0   \n",
       "2           2         608           0           42              0          0   \n",
       "3           3         642           0           35            272          0   \n",
       "4           3         836         192           84              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  SalePrice  AdjLand  Alloca  \\\n",
       "0            0         0        0       2    2008     208500        0       0   \n",
       "1            0         0        0       5    2007     181500        0       0   \n",
       "2            0         0        0       9    2008     223500        0       0   \n",
       "3            0         0        0       2    2006     140000        0       0   \n",
       "4            0         0        0      12    2008     250000        0       0   \n",
       "\n",
       "   Family  Normal  Partial  \n",
       "0       0       1        0  \n",
       "1       0       1        0  \n",
       "2       0       1        0  \n",
       "3       0       0        0  \n",
       "4       0       1        0  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelxg = xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_copy_dup_rem = final_df_copy.loc[:,~final_df_copy.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 176)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_copy_dup_rem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = final_df_copy_dup_rem.iloc[:1460,:]\n",
    "df_test = final_df_copy_dup_rem.iloc[1460:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 176)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df_test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 175)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating train features and train label from df_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['SalePrice'],axis=1)\n",
    "y_train = df_train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelxg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994490161963165"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training accuracy\n",
    "modelxg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions\n",
    "preds = modelxg.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators =[100,500,900,1100,1500]\n",
    "max_depth = [2,3,5,10,15]\n",
    "booster = ['gbtree','gblinear']\n",
    "learning_rate = [0.05,0.1,0.15,0.20]\n",
    "min_child_weight = [1,2,3,4]\n",
    "base_score =[0.25,0.5,0.75,1]\n",
    "\n",
    "\n",
    "#Defining hyperparameter grid to search\n",
    "hyperparameter_grid= {\n",
    "    'n_estimators':n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'booster':booster,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'base_score':base_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomizedSearchCv\n",
    "random_cv = RandomizedSearchCV(estimator=modelxg,\n",
    "                              param_distributions=hyperparameter_grid,\n",
    "                              cv=5,n_iter=50,\n",
    "                              scoring='neg_mean_absolute_error',\n",
    "                              verbose=2,\n",
    "                              return_train_score=True,\n",
    "                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] n_estimators=1500, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1500, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   1.0s\n",
      "[CV] n_estimators=1500, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1500, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   0.9s\n",
      "[CV] n_estimators=1500, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   0.8s\n",
      "[CV] n_estimators=1500, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   0.8s\n",
      "[CV] n_estimators=1500, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   0.8s\n",
      "[CV] n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gbtree, base_score=1, total=   1.4s\n",
      "[CV] n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gbtree, base_score=1, total=   1.4s\n",
      "[CV] n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gbtree, base_score=1, total=   1.5s\n",
      "[CV] n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gbtree, base_score=1, total=   2.3s\n",
      "[CV] n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gbtree, base_score=1, total=   2.0s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.6s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.5s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.3s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.3s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.3s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gbtree, base_score=0.5, total=   9.7s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gbtree, base_score=0.5, total=   7.9s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gbtree, base_score=0.5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gbtree, base_score=0.5, total=   7.3s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gbtree, base_score=0.5, total=   6.9s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gbtree, base_score=0.5, total=   6.8s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   4.1s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   2.6s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   2.5s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   2.4s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   2.8s\n",
      "[CV] n_estimators=100, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:30:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:30:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:30:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:30:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:30:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=1, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   0.1s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gbtree, base_score=1, total=   2.7s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gbtree, base_score=1, total=   3.0s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gbtree, base_score=1, total=   4.0s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gbtree, base_score=1, total=   2.6s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gbtree, base_score=1, total=   3.3s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=1, total=   4.2s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=1, total=   3.3s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=1, total=   2.9s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=1, total=   4.6s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=1, total=   2.5s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.25 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   1.3s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   1.0s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   1.8s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   2.0s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   1.3s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   9.3s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   8.7s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   9.1s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   9.7s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=0.25, total=  10.2s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:32:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   1.2s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:32:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.7s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:32:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.7s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:32:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   1.5s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:32:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   1.2s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   3.8s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   3.3s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   3.5s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   3.9s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   3.3s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.2, booster=gblinear, base_score=0.25 \n",
      "[01:32:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.2, booster=gblinear, base_score=0.25, total=   0.7s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.2, booster=gblinear, base_score=0.25 \n",
      "[01:32:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.2, booster=gblinear, base_score=0.25, total=   0.8s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.2, booster=gblinear, base_score=0.25 \n",
      "[01:32:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.2, booster=gblinear, base_score=0.25, total=   0.4s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.2, booster=gblinear, base_score=0.25 \n",
      "[01:32:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.2, booster=gblinear, base_score=0.25, total=   0.6s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.2, booster=gblinear, base_score=0.25 \n",
      "[01:32:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=10, learning_rate=0.2, booster=gblinear, base_score=0.25, total=   0.8s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=3, learning_rate=0.05, booster=gblinear, base_score=0.5 \n",
      "[01:32:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=3, learning_rate=0.05, booster=gblinear, base_score=0.5, total=   0.7s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=3, learning_rate=0.05, booster=gblinear, base_score=0.5 \n",
      "[01:32:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=3, learning_rate=0.05, booster=gblinear, base_score=0.5, total=   0.7s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=3, learning_rate=0.05, booster=gblinear, base_score=0.5 \n",
      "[01:32:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=3, learning_rate=0.05, booster=gblinear, base_score=0.5, total=   0.7s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=3, learning_rate=0.05, booster=gblinear, base_score=0.5 \n",
      "[01:32:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=3, learning_rate=0.05, booster=gblinear, base_score=0.5, total=   0.3s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=3, learning_rate=0.05, booster=gblinear, base_score=0.5 \n",
      "[01:32:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=3, learning_rate=0.05, booster=gblinear, base_score=0.5, total=   0.3s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=1, total=   9.6s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=1, total=  10.5s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=1, total=   9.4s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=1, total=  10.1s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=15, learning_rate=0.1, booster=gbtree, base_score=1, total=   9.7s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=2, learning_rate=0.05, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=2, learning_rate=0.05, booster=gbtree, base_score=0.25, total=   1.9s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=2, learning_rate=0.05, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=2, learning_rate=0.05, booster=gbtree, base_score=0.25, total=   1.8s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=2, learning_rate=0.05, booster=gbtree, base_score=0.25 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=2, learning_rate=0.05, booster=gbtree, base_score=0.25, total=   1.0s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=2, learning_rate=0.05, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=2, learning_rate=0.05, booster=gbtree, base_score=0.25, total=   1.9s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=2, learning_rate=0.05, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=2, learning_rate=0.05, booster=gbtree, base_score=0.25, total=   1.7s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.5, total=   1.4s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.5, total=   2.6s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.5, total=   1.5s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.5, total=   2.5s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.5, total=   3.1s\n",
      "[CV] n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   0.9s\n",
      "[CV] n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   0.5s\n",
      "[CV] n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   0.5s\n",
      "[CV] n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.1, booster=gbtree, base_score=0.25, total=   0.9s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.75 \n",
      "[01:33:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.75, total=   1.2s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.75 \n",
      "[01:33:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.75, total=   1.0s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.75 \n",
      "[01:34:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.75, total=   0.6s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.75 \n",
      "[01:34:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.75, total=   0.5s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.75 \n",
      "[01:34:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.75, total=   0.8s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5, total=   6.9s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5, total=   4.8s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5, total=   4.7s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5, total=   5.8s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5, total=   4.8s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.25 \n",
      "[01:34:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.25, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.25 \n",
      "[01:34:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.25, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.25 \n",
      "[01:34:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.25, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.25 \n",
      "[01:34:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.25, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.25 \n",
      "[01:34:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.25, total=   0.1s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:34:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.8s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:34:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   1.2s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:34:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   1.2s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:34:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   1.0s\n",
      "[CV] n_estimators=900, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:34:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.6s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.05, booster=gblinear, base_score=0.75 \n",
      "[01:34:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.05, booster=gblinear, base_score=0.75, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.05, booster=gblinear, base_score=0.75 \n",
      "[01:34:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.05, booster=gblinear, base_score=0.75, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.05, booster=gblinear, base_score=0.75 \n",
      "[01:34:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.05, booster=gblinear, base_score=0.75, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.05, booster=gblinear, base_score=0.75 \n",
      "[01:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.05, booster=gblinear, base_score=0.75, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.05, booster=gblinear, base_score=0.75 \n",
      "[01:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=2, learning_rate=0.05, booster=gblinear, base_score=0.75, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=1 \n",
      "[01:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=1, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=1 \n",
      "[01:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=1, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=1 \n",
      "[01:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=1, total=   0.1s\n",
      "[CV] n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=1 \n",
      "[01:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=1, total=   0.2s\n",
      "[CV] n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=1 \n",
      "[01:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=1, total=   0.2s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=5, learning_rate=0.05, booster=gblinear, base_score=1 \n",
      "[01:34:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=5, learning_rate=0.05, booster=gblinear, base_score=1, total=   1.2s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=5, learning_rate=0.05, booster=gblinear, base_score=1 \n",
      "[01:34:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=5, learning_rate=0.05, booster=gblinear, base_score=1, total=   1.2s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=5, learning_rate=0.05, booster=gblinear, base_score=1 \n",
      "[01:34:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=5, learning_rate=0.05, booster=gblinear, base_score=1, total=   0.7s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=5, learning_rate=0.05, booster=gblinear, base_score=1 \n",
      "[01:34:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=5, learning_rate=0.05, booster=gblinear, base_score=1, total=   0.5s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=5, learning_rate=0.05, booster=gblinear, base_score=1 \n",
      "[01:34:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=5, learning_rate=0.05, booster=gblinear, base_score=1, total=   0.6s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=1, total=   0.2s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=1, total=   0.4s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=1, total=   0.5s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=1, total=   0.5s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=1 \n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=1, total=   0.5s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.25, total=  17.3s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.25, total=  18.2s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.25, total=  16.7s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.25, total=  15.0s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.25, total=  16.4s\n",
      "[CV] n_estimators=500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25 \n",
      "[01:36:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25, total=   0.3s\n",
      "[CV] n_estimators=500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25 \n",
      "[01:36:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25, total=   0.4s\n",
      "[CV] n_estimators=500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25 \n",
      "[01:36:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25, total=   0.5s\n",
      "[CV] n_estimators=500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25 \n",
      "[01:36:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25, total=   1.1s\n",
      "[CV] n_estimators=500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25 \n",
      "[01:36:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25, total=   1.1s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:36:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.2s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:36:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.2s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:36:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.3s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:36:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.3s\n",
      "[CV] n_estimators=100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:36:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.2s\n",
      "[CV] n_estimators=500, min_child_weight=1, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:36:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=1, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.6s\n",
      "[CV] n_estimators=500, min_child_weight=1, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:36:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=1, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.4s\n",
      "[CV] n_estimators=500, min_child_weight=1, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:36:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=1, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.9s\n",
      "[CV] n_estimators=500, min_child_weight=1, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:36:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=1, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.9s\n",
      "[CV] n_estimators=500, min_child_weight=1, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:36:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=1, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.9s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.75 \n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.75, total=   1.7s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.75 \n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.75, total=   1.2s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.75 \n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.75, total=   0.9s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.75 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.75, total=   0.6s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.75 \n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.15, booster=gbtree, base_score=0.75, total=   0.7s\n",
      "[CV] n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25 \n",
      "[01:36:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25, total=   0.2s\n",
      "[CV] n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25 \n",
      "[01:36:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25, total=   0.2s\n",
      "[CV] n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25 \n",
      "[01:36:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25, total=   0.3s\n",
      "[CV] n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25 \n",
      "[01:36:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25, total=   0.3s\n",
      "[CV] n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25 \n",
      "[01:36:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=4, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.25, total=   0.3s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5, total=  15.9s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5, total=  16.5s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5, total=  20.9s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5, total=  15.2s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gbtree, base_score=0.5, total=  14.8s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=1 \n",
      "[01:37:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=1, total=   1.5s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=1 \n",
      "[01:37:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=1, total=   1.6s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=1 \n",
      "[01:37:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=1, total=   1.7s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=1 \n",
      "[01:37:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=1, total=   1.9s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=1 \n",
      "[01:37:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=1, total=   1.0s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=10, learning_rate=0.05, booster=gblinear, base_score=0.75 \n",
      "[01:37:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=10, learning_rate=0.05, booster=gblinear, base_score=0.75, total=   1.6s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=10, learning_rate=0.05, booster=gblinear, base_score=0.75 \n",
      "[01:37:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=10, learning_rate=0.05, booster=gblinear, base_score=0.75, total=   2.0s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=10, learning_rate=0.05, booster=gblinear, base_score=0.75 \n",
      "[01:37:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=10, learning_rate=0.05, booster=gblinear, base_score=0.75, total=   1.7s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=10, learning_rate=0.05, booster=gblinear, base_score=0.75 \n",
      "[01:37:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=10, learning_rate=0.05, booster=gblinear, base_score=0.75, total=   0.9s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=10, learning_rate=0.05, booster=gblinear, base_score=0.75 \n",
      "[01:37:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=10, learning_rate=0.05, booster=gblinear, base_score=0.75, total=   1.8s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.25, total=   3.8s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.25, total=   3.3s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.25, total=   3.7s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.25, total=   2.8s\n",
      "[CV] n_estimators=900, min_child_weight=3, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=900, min_child_weight=3, max_depth=3, learning_rate=0.2, booster=gbtree, base_score=0.25, total=   3.3s\n",
      "[CV] n_estimators=1100, min_child_weight=1, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.75 \n",
      "[01:38:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=1, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.75, total=   1.5s\n",
      "[CV] n_estimators=1100, min_child_weight=1, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.75 \n",
      "[01:38:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=1, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.75, total=   0.7s\n",
      "[CV] n_estimators=1100, min_child_weight=1, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.75 \n",
      "[01:38:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1100, min_child_weight=1, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.75, total=   0.7s\n",
      "[CV] n_estimators=1100, min_child_weight=1, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.75 \n",
      "[01:38:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=1, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.75, total=   1.4s\n",
      "[CV] n_estimators=1100, min_child_weight=1, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.75 \n",
      "[01:38:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=1, max_depth=2, learning_rate=0.15, booster=gblinear, base_score=0.75, total=   1.5s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:38:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.7s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:38:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.7s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:38:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.6s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:38:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.3s\n",
      "[CV] n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gblinear, base_score=0.5 \n",
      "[01:38:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=500, min_child_weight=3, max_depth=15, learning_rate=0.15, booster=gblinear, base_score=0.5, total=   0.3s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   1.5s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   2.5s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   2.8s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   2.2s\n",
      "[CV] n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=0.25 \n",
      "[CV]  n_estimators=500, min_child_weight=4, max_depth=5, learning_rate=0.15, booster=gbtree, base_score=0.25, total=   2.3s\n",
      "[CV] n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.5, total=   0.3s\n",
      "[CV] n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.5, total=   0.3s\n",
      "[CV] n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.5, total=   0.3s\n",
      "[CV] n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.5, total=   0.3s\n",
      "[CV] n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.5 \n",
      "[CV]  n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.1, booster=gbtree, base_score=0.5, total=   0.3s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=1 \n",
      "[01:38:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=1, total=   1.0s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=1 \n",
      "[01:38:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=1, total=   1.1s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=1 \n",
      "[01:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=1, total=   1.5s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=1 \n",
      "[01:38:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=1, total=   1.0s\n",
      "[CV] n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=1 \n",
      "[01:38:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=2, max_depth=3, learning_rate=0.15, booster=gblinear, base_score=1, total=   2.0s\n",
      "[CV] n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gblinear, base_score=0.25 \n",
      "[01:38:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gblinear, base_score=0.25, total=   1.5s\n",
      "[CV] n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gblinear, base_score=0.25 \n",
      "[01:38:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gblinear, base_score=0.25, total=   1.5s\n",
      "[CV] n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gblinear, base_score=0.25 \n",
      "[01:38:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gblinear, base_score=0.25, total=   1.3s\n",
      "[CV] n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gblinear, base_score=0.25 \n",
      "[01:38:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gblinear, base_score=0.25, total=   1.8s\n",
      "[CV] n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gblinear, base_score=0.25 \n",
      "[01:38:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=4, max_depth=3, learning_rate=0.1, booster=gblinear, base_score=0.25, total=   1.6s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.5 \n",
      "[01:38:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.5, total=   2.0s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.5 \n",
      "[01:38:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.5, total=   1.2s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.5 \n",
      "[01:38:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.5, total=   2.7s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.5 \n",
      "[01:39:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.5, total=   2.3s\n",
      "[CV] n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.5 \n",
      "[01:39:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=2, max_depth=15, learning_rate=0.05, booster=gblinear, base_score=0.5, total=   1.1s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=5, learning_rate=0.1, booster=gbtree, base_score=0.75 \n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=5, learning_rate=0.1, booster=gbtree, base_score=0.75, total=   4.2s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=5, learning_rate=0.1, booster=gbtree, base_score=0.75 \n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=5, learning_rate=0.1, booster=gbtree, base_score=0.75, total=   5.7s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=5, learning_rate=0.1, booster=gbtree, base_score=0.75 \n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=5, learning_rate=0.1, booster=gbtree, base_score=0.75, total=   3.7s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=5, learning_rate=0.1, booster=gbtree, base_score=0.75 \n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=5, learning_rate=0.1, booster=gbtree, base_score=0.75, total=   6.0s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=5, learning_rate=0.1, booster=gbtree, base_score=0.75 \n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=5, learning_rate=0.1, booster=gbtree, base_score=0.75, total=   5.5s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=1 \n",
      "[01:39:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=1, total=   0.7s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=1 \n",
      "[01:39:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=1, total=   0.7s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=1 \n",
      "[01:39:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=1, total=   1.7s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=1 \n",
      "[01:39:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=1, total=   2.2s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=1 \n",
      "[01:39:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=10, learning_rate=0.1, booster=gblinear, base_score=1, total=   1.4s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.25 \n",
      "[01:39:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.25, total=   1.0s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.25 \n",
      "[01:39:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.25, total=   0.9s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.25 \n",
      "[01:39:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.25, total=   1.9s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.25 \n",
      "[01:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.25, total=   1.7s\n",
      "[CV] n_estimators=900, min_child_weight=1, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.25 \n",
      "[01:39:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=900, min_child_weight=1, max_depth=5, learning_rate=0.15, booster=gblinear, base_score=0.25, total=   1.3s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:39:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   2.0s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:39:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   1.6s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:39:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   0.9s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:39:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   2.0s\n",
      "[CV] n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=0.75 \n",
      "[01:39:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=3, max_depth=2, learning_rate=0.2, booster=gblinear, base_score=0.75, total=   2.5s\n",
      "[CV] n_estimators=100, min_child_weight=3, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.5 \n",
      "[01:39:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=3, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.5, total=   0.2s\n",
      "[CV] n_estimators=100, min_child_weight=3, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.5 \n",
      "[01:39:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, min_child_weight=3, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.5, total=   0.2s\n",
      "[CV] n_estimators=100, min_child_weight=3, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.5 \n",
      "[01:39:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=3, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.5, total=   0.2s\n",
      "[CV] n_estimators=100, min_child_weight=3, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.5 \n",
      "[01:39:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=3, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.5, total=   0.2s\n",
      "[CV] n_estimators=100, min_child_weight=3, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.5 \n",
      "[01:39:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=100, min_child_weight=3, max_depth=15, learning_rate=0.2, booster=gblinear, base_score=0.5, total=   0.2s\n",
      "[CV] n_estimators=1500, min_child_weight=4, max_depth=5, learning_rate=0.1, booster=gblinear, base_score=0.5 \n",
      "[01:39:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=4, max_depth=5, learning_rate=0.1, booster=gblinear, base_score=0.5, total=   1.4s\n",
      "[CV] n_estimators=1500, min_child_weight=4, max_depth=5, learning_rate=0.1, booster=gblinear, base_score=0.5 \n",
      "[01:39:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=4, max_depth=5, learning_rate=0.1, booster=gblinear, base_score=0.5, total=   1.4s\n",
      "[CV] n_estimators=1500, min_child_weight=4, max_depth=5, learning_rate=0.1, booster=gblinear, base_score=0.5 \n",
      "[01:39:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=4, max_depth=5, learning_rate=0.1, booster=gblinear, base_score=0.5, total=   2.5s\n",
      "[CV] n_estimators=1500, min_child_weight=4, max_depth=5, learning_rate=0.1, booster=gblinear, base_score=0.5 \n",
      "[01:39:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=4, max_depth=5, learning_rate=0.1, booster=gblinear, base_score=0.5, total=   2.2s\n",
      "[CV] n_estimators=1500, min_child_weight=4, max_depth=5, learning_rate=0.1, booster=gblinear, base_score=0.5 \n",
      "[01:40:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1500, min_child_weight=4, max_depth=5, learning_rate=0.1, booster=gblinear, base_score=0.5, total=   1.5s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:40:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   0.6s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:40:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   1.4s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:40:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   1.9s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:40:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   1.9s\n",
      "[CV] n_estimators=1100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75 \n",
      "[01:40:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  n_estimators=1100, min_child_weight=2, max_depth=15, learning_rate=0.1, booster=gblinear, base_score=0.75, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          gpu_id=-1, importance_type='gain',\n",
       "                                          interaction_constraints='',\n",
       "                                          learning_rate=0.300000012,\n",
       "                                          max_delta_step=0, max_depth=6,\n",
       "                                          min_child_weight=1, missing=nan,\n",
       "                                          monotone_constraints='()',\n",
       "                                          n_estimators=100, n_jobs=8,\n",
       "                                          num_par...\n",
       "                                          tree_method='exact',\n",
       "                                          validate_parameters=1,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=2)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=900, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgregressor = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "             min_child_weight=1, monotone_constraints='()',\n",
    "             n_estimators=900, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=900, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgregressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9834541876741096"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training score\n",
    "xgregressor.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions\n",
    "preds = xgregressor.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataframe for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1461\n",
       "1       1462\n",
       "2       1463\n",
       "3       1464\n",
       "4       1465\n",
       "5       1466\n",
       "6       1467\n",
       "7       1468\n",
       "8       1469\n",
       "9       1470\n",
       "10      1471\n",
       "11      1472\n",
       "12      1473\n",
       "13      1474\n",
       "14      1475\n",
       "15      1476\n",
       "16      1477\n",
       "17      1478\n",
       "18      1479\n",
       "19      1480\n",
       "20      1481\n",
       "21      1482\n",
       "22      1483\n",
       "23      1484\n",
       "24      1485\n",
       "25      1486\n",
       "26      1487\n",
       "27      1488\n",
       "28      1489\n",
       "29      1490\n",
       "30      1491\n",
       "31      1492\n",
       "32      1493\n",
       "33      1494\n",
       "34      1495\n",
       "35      1496\n",
       "36      1497\n",
       "37      1498\n",
       "38      1499\n",
       "39      1500\n",
       "40      1501\n",
       "41      1502\n",
       "42      1503\n",
       "43      1504\n",
       "44      1505\n",
       "45      1506\n",
       "46      1507\n",
       "47      1508\n",
       "48      1509\n",
       "49      1510\n",
       "50      1511\n",
       "51      1512\n",
       "52      1513\n",
       "53      1514\n",
       "54      1515\n",
       "55      1516\n",
       "56      1517\n",
       "57      1518\n",
       "58      1519\n",
       "59      1520\n",
       "60      1521\n",
       "61      1522\n",
       "62      1523\n",
       "63      1524\n",
       "64      1525\n",
       "65      1526\n",
       "66      1527\n",
       "67      1528\n",
       "68      1529\n",
       "69      1530\n",
       "70      1531\n",
       "71      1532\n",
       "72      1533\n",
       "73      1534\n",
       "74      1535\n",
       "75      1536\n",
       "76      1537\n",
       "77      1538\n",
       "78      1539\n",
       "79      1540\n",
       "80      1541\n",
       "81      1542\n",
       "82      1543\n",
       "83      1544\n",
       "84      1545\n",
       "85      1546\n",
       "86      1547\n",
       "87      1548\n",
       "88      1549\n",
       "89      1550\n",
       "90      1551\n",
       "91      1552\n",
       "92      1553\n",
       "93      1554\n",
       "94      1555\n",
       "95      1556\n",
       "96      1557\n",
       "97      1558\n",
       "98      1559\n",
       "99      1560\n",
       "100     1561\n",
       "101     1562\n",
       "102     1563\n",
       "103     1564\n",
       "104     1565\n",
       "105     1566\n",
       "106     1567\n",
       "107     1568\n",
       "108     1569\n",
       "109     1570\n",
       "110     1571\n",
       "111     1572\n",
       "112     1573\n",
       "113     1574\n",
       "114     1575\n",
       "115     1576\n",
       "116     1577\n",
       "117     1578\n",
       "118     1579\n",
       "119     1580\n",
       "120     1581\n",
       "121     1582\n",
       "122     1583\n",
       "123     1584\n",
       "124     1585\n",
       "125     1586\n",
       "126     1587\n",
       "127     1588\n",
       "128     1589\n",
       "129     1590\n",
       "130     1591\n",
       "131     1592\n",
       "132     1593\n",
       "133     1594\n",
       "134     1595\n",
       "135     1596\n",
       "136     1597\n",
       "137     1598\n",
       "138     1599\n",
       "139     1600\n",
       "140     1601\n",
       "141     1602\n",
       "142     1603\n",
       "143     1604\n",
       "144     1605\n",
       "145     1606\n",
       "146     1607\n",
       "147     1608\n",
       "148     1609\n",
       "149     1610\n",
       "150     1611\n",
       "151     1612\n",
       "152     1613\n",
       "153     1614\n",
       "154     1615\n",
       "155     1616\n",
       "156     1617\n",
       "157     1618\n",
       "158     1619\n",
       "159     1620\n",
       "160     1621\n",
       "161     1622\n",
       "162     1623\n",
       "163     1624\n",
       "164     1625\n",
       "165     1626\n",
       "166     1627\n",
       "167     1628\n",
       "168     1629\n",
       "169     1630\n",
       "170     1631\n",
       "171     1632\n",
       "172     1633\n",
       "173     1634\n",
       "174     1635\n",
       "175     1636\n",
       "176     1637\n",
       "177     1638\n",
       "178     1639\n",
       "179     1640\n",
       "180     1641\n",
       "181     1642\n",
       "182     1643\n",
       "183     1644\n",
       "184     1645\n",
       "185     1646\n",
       "186     1647\n",
       "187     1648\n",
       "188     1649\n",
       "189     1650\n",
       "190     1651\n",
       "191     1652\n",
       "192     1653\n",
       "193     1654\n",
       "194     1655\n",
       "195     1656\n",
       "196     1657\n",
       "197     1658\n",
       "198     1659\n",
       "199     1660\n",
       "200     1661\n",
       "201     1662\n",
       "202     1663\n",
       "203     1664\n",
       "204     1665\n",
       "205     1666\n",
       "206     1667\n",
       "207     1668\n",
       "208     1669\n",
       "209     1670\n",
       "210     1671\n",
       "211     1672\n",
       "212     1673\n",
       "213     1674\n",
       "214     1675\n",
       "215     1676\n",
       "216     1677\n",
       "217     1678\n",
       "218     1679\n",
       "219     1680\n",
       "220     1681\n",
       "221     1682\n",
       "222     1683\n",
       "223     1684\n",
       "224     1685\n",
       "225     1686\n",
       "226     1687\n",
       "227     1688\n",
       "228     1689\n",
       "229     1690\n",
       "230     1691\n",
       "231     1692\n",
       "232     1693\n",
       "233     1694\n",
       "234     1695\n",
       "235     1696\n",
       "236     1697\n",
       "237     1698\n",
       "238     1699\n",
       "239     1700\n",
       "240     1701\n",
       "241     1702\n",
       "242     1703\n",
       "243     1704\n",
       "244     1705\n",
       "245     1706\n",
       "246     1707\n",
       "247     1708\n",
       "248     1709\n",
       "249     1710\n",
       "250     1711\n",
       "251     1712\n",
       "252     1713\n",
       "253     1714\n",
       "254     1715\n",
       "255     1716\n",
       "256     1717\n",
       "257     1718\n",
       "258     1719\n",
       "259     1720\n",
       "260     1721\n",
       "261     1722\n",
       "262     1723\n",
       "263     1724\n",
       "264     1725\n",
       "265     1726\n",
       "266     1727\n",
       "267     1728\n",
       "268     1729\n",
       "269     1730\n",
       "270     1731\n",
       "271     1732\n",
       "272     1733\n",
       "273     1734\n",
       "274     1735\n",
       "275     1736\n",
       "276     1737\n",
       "277     1738\n",
       "278     1739\n",
       "279     1740\n",
       "280     1741\n",
       "281     1742\n",
       "282     1743\n",
       "283     1744\n",
       "284     1745\n",
       "285     1746\n",
       "286     1747\n",
       "287     1748\n",
       "288     1749\n",
       "289     1750\n",
       "290     1751\n",
       "291     1752\n",
       "292     1753\n",
       "293     1754\n",
       "294     1755\n",
       "295     1756\n",
       "296     1757\n",
       "297     1758\n",
       "298     1759\n",
       "299     1760\n",
       "300     1761\n",
       "301     1762\n",
       "302     1763\n",
       "303     1764\n",
       "304     1765\n",
       "305     1766\n",
       "306     1767\n",
       "307     1768\n",
       "308     1769\n",
       "309     1770\n",
       "310     1771\n",
       "311     1772\n",
       "312     1773\n",
       "313     1774\n",
       "314     1775\n",
       "315     1776\n",
       "316     1777\n",
       "317     1778\n",
       "318     1779\n",
       "319     1780\n",
       "320     1781\n",
       "321     1782\n",
       "322     1783\n",
       "323     1784\n",
       "324     1785\n",
       "325     1786\n",
       "326     1787\n",
       "327     1788\n",
       "328     1789\n",
       "329     1790\n",
       "330     1791\n",
       "331     1792\n",
       "332     1793\n",
       "333     1794\n",
       "334     1795\n",
       "335     1796\n",
       "336     1797\n",
       "337     1798\n",
       "338     1799\n",
       "339     1800\n",
       "340     1801\n",
       "341     1802\n",
       "342     1803\n",
       "343     1804\n",
       "344     1805\n",
       "345     1806\n",
       "346     1807\n",
       "347     1808\n",
       "348     1809\n",
       "349     1810\n",
       "350     1811\n",
       "351     1812\n",
       "352     1813\n",
       "353     1814\n",
       "354     1815\n",
       "355     1816\n",
       "356     1817\n",
       "357     1818\n",
       "358     1819\n",
       "359     1820\n",
       "360     1821\n",
       "361     1822\n",
       "362     1823\n",
       "363     1824\n",
       "364     1825\n",
       "365     1826\n",
       "366     1827\n",
       "367     1828\n",
       "368     1829\n",
       "369     1830\n",
       "370     1831\n",
       "371     1832\n",
       "372     1833\n",
       "373     1834\n",
       "374     1835\n",
       "375     1836\n",
       "376     1837\n",
       "377     1838\n",
       "378     1839\n",
       "379     1840\n",
       "380     1841\n",
       "381     1842\n",
       "382     1843\n",
       "383     1844\n",
       "384     1845\n",
       "385     1846\n",
       "386     1847\n",
       "387     1848\n",
       "388     1849\n",
       "389     1850\n",
       "390     1851\n",
       "391     1852\n",
       "392     1853\n",
       "393     1854\n",
       "394     1855\n",
       "395     1856\n",
       "396     1857\n",
       "397     1858\n",
       "398     1859\n",
       "399     1860\n",
       "400     1861\n",
       "401     1862\n",
       "402     1863\n",
       "403     1864\n",
       "404     1865\n",
       "405     1866\n",
       "406     1867\n",
       "407     1868\n",
       "408     1869\n",
       "409     1870\n",
       "410     1871\n",
       "411     1872\n",
       "412     1873\n",
       "413     1874\n",
       "414     1875\n",
       "415     1876\n",
       "416     1877\n",
       "417     1878\n",
       "418     1879\n",
       "419     1880\n",
       "420     1881\n",
       "421     1882\n",
       "422     1883\n",
       "423     1884\n",
       "424     1885\n",
       "425     1886\n",
       "426     1887\n",
       "427     1888\n",
       "428     1889\n",
       "429     1890\n",
       "430     1891\n",
       "431     1892\n",
       "432     1893\n",
       "433     1894\n",
       "434     1895\n",
       "435     1896\n",
       "436     1897\n",
       "437     1898\n",
       "438     1899\n",
       "439     1900\n",
       "440     1901\n",
       "441     1902\n",
       "442     1903\n",
       "443     1904\n",
       "444     1905\n",
       "445     1906\n",
       "446     1907\n",
       "447     1908\n",
       "448     1909\n",
       "449     1910\n",
       "450     1911\n",
       "451     1912\n",
       "452     1913\n",
       "453     1914\n",
       "454     1915\n",
       "455     1916\n",
       "456     1917\n",
       "457     1918\n",
       "458     1919\n",
       "459     1920\n",
       "460     1921\n",
       "461     1922\n",
       "462     1923\n",
       "463     1924\n",
       "464     1925\n",
       "465     1926\n",
       "466     1927\n",
       "467     1928\n",
       "468     1929\n",
       "469     1930\n",
       "470     1931\n",
       "471     1932\n",
       "472     1933\n",
       "473     1934\n",
       "474     1935\n",
       "475     1936\n",
       "476     1937\n",
       "477     1938\n",
       "478     1939\n",
       "479     1940\n",
       "480     1941\n",
       "481     1942\n",
       "482     1943\n",
       "483     1944\n",
       "484     1945\n",
       "485     1946\n",
       "486     1947\n",
       "487     1948\n",
       "488     1949\n",
       "489     1950\n",
       "490     1951\n",
       "491     1952\n",
       "492     1953\n",
       "493     1954\n",
       "494     1955\n",
       "495     1956\n",
       "496     1957\n",
       "497     1958\n",
       "498     1959\n",
       "499     1960\n",
       "500     1961\n",
       "501     1962\n",
       "502     1963\n",
       "503     1964\n",
       "504     1965\n",
       "505     1966\n",
       "506     1967\n",
       "507     1968\n",
       "508     1969\n",
       "509     1970\n",
       "510     1971\n",
       "511     1972\n",
       "512     1973\n",
       "513     1974\n",
       "514     1975\n",
       "515     1976\n",
       "516     1977\n",
       "517     1978\n",
       "518     1979\n",
       "519     1980\n",
       "520     1981\n",
       "521     1982\n",
       "522     1983\n",
       "523     1984\n",
       "524     1985\n",
       "525     1986\n",
       "526     1987\n",
       "527     1988\n",
       "528     1989\n",
       "529     1990\n",
       "530     1991\n",
       "531     1992\n",
       "532     1993\n",
       "533     1994\n",
       "534     1995\n",
       "535     1996\n",
       "536     1997\n",
       "537     1998\n",
       "538     1999\n",
       "539     2000\n",
       "540     2001\n",
       "541     2002\n",
       "542     2003\n",
       "543     2004\n",
       "544     2005\n",
       "545     2006\n",
       "546     2007\n",
       "547     2008\n",
       "548     2009\n",
       "549     2010\n",
       "550     2011\n",
       "551     2012\n",
       "552     2013\n",
       "553     2014\n",
       "554     2015\n",
       "555     2016\n",
       "556     2017\n",
       "557     2018\n",
       "558     2019\n",
       "559     2020\n",
       "560     2021\n",
       "561     2022\n",
       "562     2023\n",
       "563     2024\n",
       "564     2025\n",
       "565     2026\n",
       "566     2027\n",
       "567     2028\n",
       "568     2029\n",
       "569     2030\n",
       "570     2031\n",
       "571     2032\n",
       "572     2033\n",
       "573     2034\n",
       "574     2035\n",
       "575     2036\n",
       "576     2037\n",
       "577     2038\n",
       "578     2039\n",
       "579     2040\n",
       "580     2041\n",
       "581     2042\n",
       "582     2043\n",
       "583     2044\n",
       "584     2045\n",
       "585     2046\n",
       "586     2047\n",
       "587     2048\n",
       "588     2049\n",
       "589     2050\n",
       "590     2051\n",
       "591     2052\n",
       "592     2053\n",
       "593     2054\n",
       "594     2055\n",
       "595     2056\n",
       "596     2057\n",
       "597     2058\n",
       "598     2059\n",
       "599     2060\n",
       "600     2061\n",
       "601     2062\n",
       "602     2063\n",
       "603     2064\n",
       "604     2065\n",
       "605     2066\n",
       "606     2067\n",
       "607     2068\n",
       "608     2069\n",
       "609     2070\n",
       "610     2071\n",
       "611     2072\n",
       "612     2073\n",
       "613     2074\n",
       "614     2075\n",
       "615     2076\n",
       "616     2077\n",
       "617     2078\n",
       "618     2079\n",
       "619     2080\n",
       "620     2081\n",
       "621     2082\n",
       "622     2083\n",
       "623     2084\n",
       "624     2085\n",
       "625     2086\n",
       "626     2087\n",
       "627     2088\n",
       "628     2089\n",
       "629     2090\n",
       "630     2091\n",
       "631     2092\n",
       "632     2093\n",
       "633     2094\n",
       "634     2095\n",
       "635     2096\n",
       "636     2097\n",
       "637     2098\n",
       "638     2099\n",
       "639     2100\n",
       "640     2101\n",
       "641     2102\n",
       "642     2103\n",
       "643     2104\n",
       "644     2105\n",
       "645     2106\n",
       "646     2107\n",
       "647     2108\n",
       "648     2109\n",
       "649     2110\n",
       "650     2111\n",
       "651     2112\n",
       "652     2113\n",
       "653     2114\n",
       "654     2115\n",
       "655     2116\n",
       "656     2117\n",
       "657     2118\n",
       "658     2119\n",
       "659     2120\n",
       "660     2121\n",
       "661     2122\n",
       "662     2123\n",
       "663     2124\n",
       "664     2125\n",
       "665     2126\n",
       "666     2127\n",
       "667     2128\n",
       "668     2129\n",
       "669     2130\n",
       "670     2131\n",
       "671     2132\n",
       "672     2133\n",
       "673     2134\n",
       "674     2135\n",
       "675     2136\n",
       "676     2137\n",
       "677     2138\n",
       "678     2139\n",
       "679     2140\n",
       "680     2141\n",
       "681     2142\n",
       "682     2143\n",
       "683     2144\n",
       "684     2145\n",
       "685     2146\n",
       "686     2147\n",
       "687     2148\n",
       "688     2149\n",
       "689     2150\n",
       "690     2151\n",
       "691     2152\n",
       "692     2153\n",
       "693     2154\n",
       "694     2155\n",
       "695     2156\n",
       "696     2157\n",
       "697     2158\n",
       "698     2159\n",
       "699     2160\n",
       "700     2161\n",
       "701     2162\n",
       "702     2163\n",
       "703     2164\n",
       "704     2165\n",
       "705     2166\n",
       "706     2167\n",
       "707     2168\n",
       "708     2169\n",
       "709     2170\n",
       "710     2171\n",
       "711     2172\n",
       "712     2173\n",
       "713     2174\n",
       "714     2175\n",
       "715     2176\n",
       "716     2177\n",
       "717     2178\n",
       "718     2179\n",
       "719     2180\n",
       "720     2181\n",
       "721     2182\n",
       "722     2183\n",
       "723     2184\n",
       "724     2185\n",
       "725     2186\n",
       "726     2187\n",
       "727     2188\n",
       "728     2189\n",
       "729     2190\n",
       "730     2191\n",
       "731     2192\n",
       "732     2193\n",
       "733     2194\n",
       "734     2195\n",
       "735     2196\n",
       "736     2197\n",
       "737     2198\n",
       "738     2199\n",
       "739     2200\n",
       "740     2201\n",
       "741     2202\n",
       "742     2203\n",
       "743     2204\n",
       "744     2205\n",
       "745     2206\n",
       "746     2207\n",
       "747     2208\n",
       "748     2209\n",
       "749     2210\n",
       "750     2211\n",
       "751     2212\n",
       "752     2213\n",
       "753     2214\n",
       "754     2215\n",
       "755     2216\n",
       "756     2217\n",
       "757     2218\n",
       "758     2219\n",
       "759     2220\n",
       "760     2221\n",
       "761     2222\n",
       "762     2223\n",
       "763     2224\n",
       "764     2225\n",
       "765     2226\n",
       "766     2227\n",
       "767     2228\n",
       "768     2229\n",
       "769     2230\n",
       "770     2231\n",
       "771     2232\n",
       "772     2233\n",
       "773     2234\n",
       "774     2235\n",
       "775     2236\n",
       "776     2237\n",
       "777     2238\n",
       "778     2239\n",
       "779     2240\n",
       "780     2241\n",
       "781     2242\n",
       "782     2243\n",
       "783     2244\n",
       "784     2245\n",
       "785     2246\n",
       "786     2247\n",
       "787     2248\n",
       "788     2249\n",
       "789     2250\n",
       "790     2251\n",
       "791     2252\n",
       "792     2253\n",
       "793     2254\n",
       "794     2255\n",
       "795     2256\n",
       "796     2257\n",
       "797     2258\n",
       "798     2259\n",
       "799     2260\n",
       "800     2261\n",
       "801     2262\n",
       "802     2263\n",
       "803     2264\n",
       "804     2265\n",
       "805     2266\n",
       "806     2267\n",
       "807     2268\n",
       "808     2269\n",
       "809     2270\n",
       "810     2271\n",
       "811     2272\n",
       "812     2273\n",
       "813     2274\n",
       "814     2275\n",
       "815     2276\n",
       "816     2277\n",
       "817     2278\n",
       "818     2279\n",
       "819     2280\n",
       "820     2281\n",
       "821     2282\n",
       "822     2283\n",
       "823     2284\n",
       "824     2285\n",
       "825     2286\n",
       "826     2287\n",
       "827     2288\n",
       "828     2289\n",
       "829     2290\n",
       "830     2291\n",
       "831     2292\n",
       "832     2293\n",
       "833     2294\n",
       "834     2295\n",
       "835     2296\n",
       "836     2297\n",
       "837     2298\n",
       "838     2299\n",
       "839     2300\n",
       "840     2301\n",
       "841     2302\n",
       "842     2303\n",
       "843     2304\n",
       "844     2305\n",
       "845     2306\n",
       "846     2307\n",
       "847     2308\n",
       "848     2309\n",
       "849     2310\n",
       "850     2311\n",
       "851     2312\n",
       "852     2313\n",
       "853     2314\n",
       "854     2315\n",
       "855     2316\n",
       "856     2317\n",
       "857     2318\n",
       "858     2319\n",
       "859     2320\n",
       "860     2321\n",
       "861     2322\n",
       "862     2323\n",
       "863     2324\n",
       "864     2325\n",
       "865     2326\n",
       "866     2327\n",
       "867     2328\n",
       "868     2329\n",
       "869     2330\n",
       "870     2331\n",
       "871     2332\n",
       "872     2333\n",
       "873     2334\n",
       "874     2335\n",
       "875     2336\n",
       "876     2337\n",
       "877     2338\n",
       "878     2339\n",
       "879     2340\n",
       "880     2341\n",
       "881     2342\n",
       "882     2343\n",
       "883     2344\n",
       "884     2345\n",
       "885     2346\n",
       "886     2347\n",
       "887     2348\n",
       "888     2349\n",
       "889     2350\n",
       "890     2351\n",
       "891     2352\n",
       "892     2353\n",
       "893     2354\n",
       "894     2355\n",
       "895     2356\n",
       "896     2357\n",
       "897     2358\n",
       "898     2359\n",
       "899     2360\n",
       "900     2361\n",
       "901     2362\n",
       "902     2363\n",
       "903     2364\n",
       "904     2365\n",
       "905     2366\n",
       "906     2367\n",
       "907     2368\n",
       "908     2369\n",
       "909     2370\n",
       "910     2371\n",
       "911     2372\n",
       "912     2373\n",
       "913     2374\n",
       "914     2375\n",
       "915     2376\n",
       "916     2377\n",
       "917     2378\n",
       "918     2379\n",
       "919     2380\n",
       "920     2381\n",
       "921     2382\n",
       "922     2383\n",
       "923     2384\n",
       "924     2385\n",
       "925     2386\n",
       "926     2387\n",
       "927     2388\n",
       "928     2389\n",
       "929     2390\n",
       "930     2391\n",
       "931     2392\n",
       "932     2393\n",
       "933     2394\n",
       "934     2395\n",
       "935     2396\n",
       "936     2397\n",
       "937     2398\n",
       "938     2399\n",
       "939     2400\n",
       "940     2401\n",
       "941     2402\n",
       "942     2403\n",
       "943     2404\n",
       "944     2405\n",
       "945     2406\n",
       "946     2407\n",
       "947     2408\n",
       "948     2409\n",
       "949     2410\n",
       "950     2411\n",
       "951     2412\n",
       "952     2413\n",
       "953     2414\n",
       "954     2415\n",
       "955     2416\n",
       "956     2417\n",
       "957     2418\n",
       "958     2419\n",
       "959     2420\n",
       "960     2421\n",
       "961     2422\n",
       "962     2423\n",
       "963     2424\n",
       "964     2425\n",
       "965     2426\n",
       "966     2427\n",
       "967     2428\n",
       "968     2429\n",
       "969     2430\n",
       "970     2431\n",
       "971     2432\n",
       "972     2433\n",
       "973     2434\n",
       "974     2435\n",
       "975     2436\n",
       "976     2437\n",
       "977     2438\n",
       "978     2439\n",
       "979     2440\n",
       "980     2441\n",
       "981     2442\n",
       "982     2443\n",
       "983     2444\n",
       "984     2445\n",
       "985     2446\n",
       "986     2447\n",
       "987     2448\n",
       "988     2449\n",
       "989     2450\n",
       "990     2451\n",
       "991     2452\n",
       "992     2453\n",
       "993     2454\n",
       "994     2455\n",
       "995     2456\n",
       "996     2457\n",
       "997     2458\n",
       "998     2459\n",
       "999     2460\n",
       "1000    2461\n",
       "1001    2462\n",
       "1002    2463\n",
       "1003    2464\n",
       "1004    2465\n",
       "1005    2466\n",
       "1006    2467\n",
       "1007    2468\n",
       "1008    2469\n",
       "1009    2470\n",
       "1010    2471\n",
       "1011    2472\n",
       "1012    2473\n",
       "1013    2474\n",
       "1014    2475\n",
       "1015    2476\n",
       "1016    2477\n",
       "1017    2478\n",
       "1018    2479\n",
       "1019    2480\n",
       "1020    2481\n",
       "1021    2482\n",
       "1022    2483\n",
       "1023    2484\n",
       "1024    2485\n",
       "1025    2486\n",
       "1026    2487\n",
       "1027    2488\n",
       "1028    2489\n",
       "1029    2490\n",
       "1030    2491\n",
       "1031    2492\n",
       "1032    2493\n",
       "1033    2494\n",
       "1034    2495\n",
       "1035    2496\n",
       "1036    2497\n",
       "1037    2498\n",
       "1038    2499\n",
       "1039    2500\n",
       "1040    2501\n",
       "1041    2502\n",
       "1042    2503\n",
       "1043    2504\n",
       "1044    2505\n",
       "1045    2506\n",
       "1046    2507\n",
       "1047    2508\n",
       "1048    2509\n",
       "1049    2510\n",
       "1050    2511\n",
       "1051    2512\n",
       "1052    2513\n",
       "1053    2514\n",
       "1054    2515\n",
       "1055    2516\n",
       "1056    2517\n",
       "1057    2518\n",
       "1058    2519\n",
       "1059    2520\n",
       "1060    2521\n",
       "1061    2522\n",
       "1062    2523\n",
       "1063    2524\n",
       "1064    2525\n",
       "1065    2526\n",
       "1066    2527\n",
       "1067    2528\n",
       "1068    2529\n",
       "1069    2530\n",
       "1070    2531\n",
       "1071    2532\n",
       "1072    2533\n",
       "1073    2534\n",
       "1074    2535\n",
       "1075    2536\n",
       "1076    2537\n",
       "1077    2538\n",
       "1078    2539\n",
       "1079    2540\n",
       "1080    2541\n",
       "1081    2542\n",
       "1082    2543\n",
       "1083    2544\n",
       "1084    2545\n",
       "1085    2546\n",
       "1086    2547\n",
       "1087    2548\n",
       "1088    2549\n",
       "1089    2550\n",
       "1090    2551\n",
       "1091    2552\n",
       "1092    2553\n",
       "1093    2554\n",
       "1094    2555\n",
       "1095    2556\n",
       "1096    2557\n",
       "1097    2558\n",
       "1098    2559\n",
       "1099    2560\n",
       "1100    2561\n",
       "1101    2562\n",
       "1102    2563\n",
       "1103    2564\n",
       "1104    2565\n",
       "1105    2566\n",
       "1106    2567\n",
       "1107    2568\n",
       "1108    2569\n",
       "1109    2570\n",
       "1110    2571\n",
       "1111    2572\n",
       "1112    2573\n",
       "1113    2574\n",
       "1114    2575\n",
       "1115    2576\n",
       "1116    2577\n",
       "1117    2578\n",
       "1118    2579\n",
       "1119    2580\n",
       "1120    2581\n",
       "1121    2582\n",
       "1122    2583\n",
       "1123    2584\n",
       "1124    2585\n",
       "1125    2586\n",
       "1126    2587\n",
       "1127    2588\n",
       "1128    2589\n",
       "1129    2590\n",
       "1130    2591\n",
       "1131    2592\n",
       "1132    2593\n",
       "1133    2594\n",
       "1134    2595\n",
       "1135    2596\n",
       "1136    2597\n",
       "1137    2598\n",
       "1138    2599\n",
       "1139    2600\n",
       "1140    2601\n",
       "1141    2602\n",
       "1142    2603\n",
       "1143    2604\n",
       "1144    2605\n",
       "1145    2606\n",
       "1146    2607\n",
       "1147    2608\n",
       "1148    2609\n",
       "1149    2610\n",
       "1150    2611\n",
       "1151    2612\n",
       "1152    2613\n",
       "1153    2614\n",
       "1154    2615\n",
       "1155    2616\n",
       "1156    2617\n",
       "1157    2618\n",
       "1158    2619\n",
       "1159    2620\n",
       "1160    2621\n",
       "1161    2622\n",
       "1162    2623\n",
       "1163    2624\n",
       "1164    2625\n",
       "1165    2626\n",
       "1166    2627\n",
       "1167    2628\n",
       "1168    2629\n",
       "1169    2630\n",
       "1170    2631\n",
       "1171    2632\n",
       "1172    2633\n",
       "1173    2634\n",
       "1174    2635\n",
       "1175    2636\n",
       "1176    2637\n",
       "1177    2638\n",
       "1178    2639\n",
       "1179    2640\n",
       "1180    2641\n",
       "1181    2642\n",
       "1182    2643\n",
       "1183    2644\n",
       "1184    2645\n",
       "1185    2646\n",
       "1186    2647\n",
       "1187    2648\n",
       "1188    2649\n",
       "1189    2650\n",
       "1190    2651\n",
       "1191    2652\n",
       "1192    2653\n",
       "1193    2654\n",
       "1194    2655\n",
       "1195    2656\n",
       "1196    2657\n",
       "1197    2658\n",
       "1198    2659\n",
       "1199    2660\n",
       "1200    2661\n",
       "1201    2662\n",
       "1202    2663\n",
       "1203    2664\n",
       "1204    2665\n",
       "1205    2666\n",
       "1206    2667\n",
       "1207    2668\n",
       "1208    2669\n",
       "1209    2670\n",
       "1210    2671\n",
       "1211    2672\n",
       "1212    2673\n",
       "1213    2674\n",
       "1214    2675\n",
       "1215    2676\n",
       "1216    2677\n",
       "1217    2678\n",
       "1218    2679\n",
       "1219    2680\n",
       "1220    2681\n",
       "1221    2682\n",
       "1222    2683\n",
       "1223    2684\n",
       "1224    2685\n",
       "1225    2686\n",
       "1226    2687\n",
       "1227    2688\n",
       "1228    2689\n",
       "1229    2690\n",
       "1230    2691\n",
       "1231    2692\n",
       "1232    2693\n",
       "1233    2694\n",
       "1234    2695\n",
       "1235    2696\n",
       "1236    2697\n",
       "1237    2698\n",
       "1238    2699\n",
       "1239    2700\n",
       "1240    2701\n",
       "1241    2702\n",
       "1242    2703\n",
       "1243    2704\n",
       "1244    2705\n",
       "1245    2706\n",
       "1246    2707\n",
       "1247    2708\n",
       "1248    2709\n",
       "1249    2710\n",
       "1250    2711\n",
       "1251    2712\n",
       "1252    2713\n",
       "1253    2714\n",
       "1254    2715\n",
       "1255    2716\n",
       "1256    2717\n",
       "1257    2718\n",
       "1258    2719\n",
       "1259    2720\n",
       "1260    2721\n",
       "1261    2722\n",
       "1262    2723\n",
       "1263    2724\n",
       "1264    2725\n",
       "1265    2726\n",
       "1266    2727\n",
       "1267    2728\n",
       "1268    2729\n",
       "1269    2730\n",
       "1270    2731\n",
       "1271    2732\n",
       "1272    2733\n",
       "1273    2734\n",
       "1274    2735\n",
       "1275    2736\n",
       "1276    2737\n",
       "1277    2738\n",
       "1278    2739\n",
       "1279    2740\n",
       "1280    2741\n",
       "1281    2742\n",
       "1282    2743\n",
       "1283    2744\n",
       "1284    2745\n",
       "1285    2746\n",
       "1286    2747\n",
       "1287    2748\n",
       "1288    2749\n",
       "1289    2750\n",
       "1290    2751\n",
       "1291    2752\n",
       "1292    2753\n",
       "1293    2754\n",
       "1294    2755\n",
       "1295    2756\n",
       "1296    2757\n",
       "1297    2758\n",
       "1298    2759\n",
       "1299    2760\n",
       "1300    2761\n",
       "1301    2762\n",
       "1302    2763\n",
       "1303    2764\n",
       "1304    2765\n",
       "1305    2766\n",
       "1306    2767\n",
       "1307    2768\n",
       "1308    2769\n",
       "1309    2770\n",
       "1310    2771\n",
       "1311    2772\n",
       "1312    2773\n",
       "1313    2774\n",
       "1314    2775\n",
       "1315    2776\n",
       "1316    2777\n",
       "1317    2778\n",
       "1318    2779\n",
       "1319    2780\n",
       "1320    2781\n",
       "1321    2782\n",
       "1322    2783\n",
       "1323    2784\n",
       "1324    2785\n",
       "1325    2786\n",
       "1326    2787\n",
       "1327    2788\n",
       "1328    2789\n",
       "1329    2790\n",
       "1330    2791\n",
       "1331    2792\n",
       "1332    2793\n",
       "1333    2794\n",
       "1334    2795\n",
       "1335    2796\n",
       "1336    2797\n",
       "1337    2798\n",
       "1338    2799\n",
       "1339    2800\n",
       "1340    2801\n",
       "1341    2802\n",
       "1342    2803\n",
       "1343    2804\n",
       "1344    2805\n",
       "1345    2806\n",
       "1346    2807\n",
       "1347    2808\n",
       "1348    2809\n",
       "1349    2810\n",
       "1350    2811\n",
       "1351    2812\n",
       "1352    2813\n",
       "1353    2814\n",
       "1354    2815\n",
       "1355    2816\n",
       "1356    2817\n",
       "1357    2818\n",
       "1358    2819\n",
       "1359    2820\n",
       "1360    2821\n",
       "1361    2822\n",
       "1362    2823\n",
       "1363    2824\n",
       "1364    2825\n",
       "1365    2826\n",
       "1366    2827\n",
       "1367    2828\n",
       "1368    2829\n",
       "1369    2830\n",
       "1370    2831\n",
       "1371    2832\n",
       "1372    2833\n",
       "1373    2834\n",
       "1374    2835\n",
       "1375    2836\n",
       "1376    2837\n",
       "1377    2838\n",
       "1378    2839\n",
       "1379    2840\n",
       "1380    2841\n",
       "1381    2842\n",
       "1382    2843\n",
       "1383    2844\n",
       "1384    2845\n",
       "1385    2846\n",
       "1386    2847\n",
       "1387    2848\n",
       "1388    2849\n",
       "1389    2850\n",
       "1390    2851\n",
       "1391    2852\n",
       "1392    2853\n",
       "1393    2854\n",
       "1394    2855\n",
       "1395    2856\n",
       "1396    2857\n",
       "1397    2858\n",
       "1398    2859\n",
       "1399    2860\n",
       "1400    2861\n",
       "1401    2862\n",
       "1402    2863\n",
       "1403    2864\n",
       "1404    2865\n",
       "1405    2866\n",
       "1406    2867\n",
       "1407    2868\n",
       "1408    2869\n",
       "1409    2870\n",
       "1410    2871\n",
       "1411    2872\n",
       "1412    2873\n",
       "1413    2874\n",
       "1414    2875\n",
       "1415    2876\n",
       "1416    2877\n",
       "1417    2878\n",
       "1418    2879\n",
       "1419    2880\n",
       "1420    2881\n",
       "1421    2882\n",
       "1422    2883\n",
       "1423    2884\n",
       "1424    2885\n",
       "1425    2886\n",
       "1426    2887\n",
       "1427    2888\n",
       "1428    2889\n",
       "1429    2890\n",
       "1430    2891\n",
       "1431    2892\n",
       "1432    2893\n",
       "1433    2894\n",
       "1434    2895\n",
       "1435    2896\n",
       "1436    2897\n",
       "1437    2898\n",
       "1438    2899\n",
       "1439    2900\n",
       "1440    2901\n",
       "1441    2902\n",
       "1442    2903\n",
       "1443    2904\n",
       "1444    2905\n",
       "1445    2906\n",
       "1446    2907\n",
       "1447    2908\n",
       "1448    2909\n",
       "1449    2910\n",
       "1450    2911\n",
       "1451    2912\n",
       "1452    2913\n",
       "1453    2914\n",
       "1454    2915\n",
       "1455    2916\n",
       "1456    2917\n",
       "1457    2918\n",
       "1458    2919\n",
       "Name: Id, dtype: int64"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame()\n",
    "submission_df['Id'] = test['Id']\n",
    "submission_df['SalePrice'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>120293.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>160784.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>186468.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>193961.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>199362.593750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  120293.859375\n",
       "1  1462  160784.328125\n",
       "2  1463  186468.062500\n",
       "3  1464  193961.453125\n",
       "4  1465  199362.593750"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('kaggle_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
